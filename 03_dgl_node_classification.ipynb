{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import dgl\r\n",
    "import dgl.data\r\n",
    "import dgl.nn as gnn\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Датасет Cora: \r\n",
    "* узлы - статьи\r\n",
    "* связи - цитирование одной статьей другой\r\n",
    "* каждый узел в качестве фичей содержит нормализованный word count vector \r\n",
    "\r\n",
    "Датасет может состоять из одного или нескольких графов. Cora состоит из одного.\r\n",
    "\r\n",
    "Граф в DGL может хранить фичи для узлов и ребер в виде словарей `ndata` и `edata`. \r\n",
    "\r\n",
    "Фичи узлов в Cora:\r\n",
    "* x_mask - булев тензор, показывающий, входит ли узел в множество x (train, val, test)\r\n",
    "* label - метка узла\r\n",
    "* feat - фичи узла"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "dataset = dgl.data.CoraGraphDataset()\r\n",
    "G = dataset[0]\r\n",
    "\r\n",
    "print(f\"Кол-во категорий: {dataset.num_classes}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "Кол-во категорий: 7\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class GCN(nn.Module):\r\n",
    "    def __init__(self, n_input, n_hidden, n_output):\r\n",
    "        super().__init__()\r\n",
    "        self.conv1 = gnn.GraphConv(n_input, n_hidden)\r\n",
    "        self.conv2 = gnn.GraphConv(n_hidden, n_output)\r\n",
    "    \r\n",
    "    def forward(self, G, in_features):\r\n",
    "        out = F.relu(self.conv1(G, in_features))\r\n",
    "        out = self.conv2(G, out)\r\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "n_input = G.ndata['feat'].shape[1]\r\n",
    "n_hidden = 16\r\n",
    "n_out = dataset.num_classes\r\n",
    "n_epochs = 100\r\n",
    "\r\n",
    "model = GCN(n_input, n_hidden, n_out)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# check\r\n",
    "model(G, G.ndata['feat']).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2708, 7])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "model = GCN(n_input, n_hidden, n_out)\r\n",
    "\r\n",
    "optimizer = optim.Adam(model.parameters(), lr=.01)\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "best_val_acc, best_test_acc = 0, 0\r\n",
    "\r\n",
    "\r\n",
    "features = G.ndata['feat']\r\n",
    "labels = G.ndata['label']\r\n",
    "train_mask = G.ndata['train_mask']\r\n",
    "val_mask = G.ndata['val_mask']\r\n",
    "test_mask = G.ndata['test_mask']\r\n",
    "\r\n",
    "for epoch in range(n_epochs):\r\n",
    "    # forward\r\n",
    "    logits = model(G, features)\r\n",
    "    \r\n",
    "    # loss\r\n",
    "    loss = criterion(logits[train_mask], labels[train_mask])\r\n",
    "\r\n",
    "    # backward\r\n",
    "    loss.backward()\r\n",
    "    optimizer.step()\r\n",
    "    optimizer.zero_grad()\r\n",
    "\r\n",
    "    # eval\r\n",
    "    with torch.no_grad():\r\n",
    "        predictions = logits.argmax(dim=1)\r\n",
    "        train_acc = (predictions[train_mask] == labels[train_mask]).float().mean()\r\n",
    "        val_acc = (predictions[val_mask] == labels[val_mask]).float().mean()\r\n",
    "        test_acc = (predictions[test_mask] == labels[test_mask]).float().mean()\r\n",
    "\r\n",
    "        if best_val_acc < val_acc:\r\n",
    "            best_val_acc = val_acc\r\n",
    "            best_test_acc = test_acc\r\n",
    "\r\n",
    "    if not epoch % 5:\r\n",
    "        print(f'In epoch {epoch}, loss: {loss:.3f}, val acc: {val_acc:.3f} (best {best_val_acc:.3f}), test acc: {test_acc:.3f} (best {best_test_acc:.3f})')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In epoch 0, loss: 1.945, val acc: 0.172 (best 0.172), test acc: 0.159 (best 0.159)\n",
      "In epoch 5, loss: 1.886, val acc: 0.516 (best 0.540), test acc: 0.527 (best 0.546)\n",
      "In epoch 10, loss: 1.804, val acc: 0.590 (best 0.590), test acc: 0.612 (best 0.612)\n",
      "In epoch 15, loss: 1.699, val acc: 0.622 (best 0.622), test acc: 0.631 (best 0.631)\n",
      "In epoch 20, loss: 1.572, val acc: 0.636 (best 0.636), test acc: 0.646 (best 0.646)\n",
      "In epoch 25, loss: 1.425, val acc: 0.644 (best 0.646), test acc: 0.657 (best 0.656)\n",
      "In epoch 30, loss: 1.263, val acc: 0.658 (best 0.658), test acc: 0.673 (best 0.668)\n",
      "In epoch 35, loss: 1.094, val acc: 0.692 (best 0.692), test acc: 0.694 (best 0.694)\n",
      "In epoch 40, loss: 0.927, val acc: 0.704 (best 0.704), test acc: 0.712 (best 0.712)\n",
      "In epoch 45, loss: 0.771, val acc: 0.718 (best 0.718), test acc: 0.725 (best 0.723)\n",
      "In epoch 50, loss: 0.632, val acc: 0.730 (best 0.730), test acc: 0.740 (best 0.740)\n",
      "In epoch 55, loss: 0.515, val acc: 0.754 (best 0.754), test acc: 0.761 (best 0.761)\n",
      "In epoch 60, loss: 0.417, val acc: 0.758 (best 0.758), test acc: 0.768 (best 0.765)\n",
      "In epoch 65, loss: 0.338, val acc: 0.770 (best 0.770), test acc: 0.777 (best 0.777)\n",
      "In epoch 70, loss: 0.274, val acc: 0.780 (best 0.780), test acc: 0.784 (best 0.784)\n",
      "In epoch 75, loss: 0.224, val acc: 0.786 (best 0.786), test acc: 0.789 (best 0.789)\n",
      "In epoch 80, loss: 0.184, val acc: 0.794 (best 0.794), test acc: 0.789 (best 0.789)\n",
      "In epoch 85, loss: 0.152, val acc: 0.794 (best 0.794), test acc: 0.790 (best 0.789)\n",
      "In epoch 90, loss: 0.127, val acc: 0.794 (best 0.794), test acc: 0.794 (best 0.789)\n",
      "In epoch 95, loss: 0.107, val acc: 0.790 (best 0.794), test acc: 0.795 (best 0.789)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "labels.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2708])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('gcn': conda)"
  },
  "interpreter": {
   "hash": "a5d512aadeb6aaabeaf2234f39752bedcd0c0a511f474f5ce732b89a77e68aba"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}