{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение GNN для классификации графов с использованием PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\gcn\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import TUDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# несколько удобных функций для описания датасетов\n",
    "def describe_dataset(dataset):\n",
    "    print(f'Dataset: {dataset}:')\n",
    "    print('======================')\n",
    "    print(f'Number of graphs: {len(dataset)}')\n",
    "    print(f'Number of features: {dataset.num_features}')\n",
    "    print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "def describe_graph(g):\n",
    "    print(g)\n",
    "    print('==============================================================')\n",
    "\n",
    "    # Gather some statistics about the graph.\n",
    "    print(f'Number of nodes: {g.num_nodes}')\n",
    "    print(f'Number of edges: {g.num_edges}')\n",
    "    print(f'Average node degree: {g.num_edges / g.num_nodes:.2f}')\n",
    "    if hasattr(g, 'train_mask'):\n",
    "        print(f'Number of training nodes: {g.train_mask.sum()}')\n",
    "        print(f'Training node label rate: {int(g.train_mask.sum()) / g.num_nodes:.2f}')\n",
    "    print(f'Has isolated nodes: {g.has_isolated_nodes()}')\n",
    "    print(f'Has self-loops: {g.has_self_loops()}')\n",
    "    print(f'Is undirected: {g.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: MUTAG(188):\n",
      "======================\n",
      "Number of graphs: 188\n",
      "Number of features: 7\n",
      "Number of classes: 2\n",
      "Data(edge_index=[2, 38], x=[17, 7], edge_attr=[38, 4], y=[1])\n",
      "==============================================================\n",
      "Number of nodes: 17\n",
      "Number of edges: 38\n",
      "Average node degree: 2.24\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "dataset = TUDataset(root='./tmp/TUDataset', name='MUTAG')\n",
    "g = dataset[0]\n",
    "describe_dataset(dataset)\n",
    "describe_graph(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что для графа имеется одна метка y=[1], которую нам и нужно уметь предсказывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перемешиваем датасет и разбиваем на обучающее и тестовое множество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train=150\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle()\n",
    "n_train = len(dataset) * 8 // 10\n",
    "print(f'{n_train=}')\n",
    "train_dataset = dataset[: n_train]\n",
    "test_dataset = dataset[n_train: ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для получения пакетов из графов используем  `torch_geometric.loader.DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(edge_index=[2, 2570], x=[1167, 7], edge_attr=[2570, 4], y=[64], batch=[1167], ptr=[65])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При решении задачи классификации графов появляется дополнительный шаг - агрегация эмбеддингов узлов (readout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.nn as gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1167, 5])\n",
      "torch.Size([64, 5])\n"
     ]
    }
   ],
   "source": [
    "# 1. Получение эмбеддингов узлов\n",
    "layer = gnn.GCNConv(in_channels=7, out_channels=5)\n",
    "h_e = layer(batch.x, batch.edge_index)\n",
    "print(h_e.shape)\n",
    "# 2. Шаг агрегации (readout)\n",
    "h_g = gnn.global_mean_pool(h_e, batch.batch)\n",
    "print(h_g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_geometric.nn as gnn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        n_input: int, \n",
    "        n_hidden_layers: int, \n",
    "        n_hidden: int, \n",
    "        n_out: int,\n",
    "        n_classes: int,\n",
    "        dropout_p: float = 0.2,\n",
    "        activation: callable = F.relu\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout_p = dropout_p\n",
    "        self.activation = activation\n",
    "        # подход к построению глубоких GNN взят отсюда: \n",
    "        # https://github.com/dmlc/dgl/blob/master/examples/pytorch/graphsage/advanced/model.py\n",
    "        self.layers = nn.ModuleList()\n",
    "        if n_hidden_layers > 1:\n",
    "            self.layers.append(gnn.GCNConv(n_input, n_hidden))\n",
    "            for _ in range(1, n_hidden_layers-1):\n",
    "                self.layers.append(gnn.GCNConv(n_hidden, n_hidden))\n",
    "            self.layers.append(gnn.GCNConv(n_hidden, n_out))\n",
    "        else:\n",
    "            self.layers.append(gnn.GCNConv(n_input, n_out))\n",
    "        self.classifier = nn.Linear(n_out, n_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Получение эмбеддингов узлов\n",
    "        h = x\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, edge_index)\n",
    "            h = self.activation(h)\n",
    "            h = F.dropout(h, p=self.dropout_p, training=self.training)\n",
    "        \n",
    "        # 2. Агрегация\n",
    "        h = gnn.global_mean_pool(h, batch)\n",
    "        h = F.dropout(h, p=self.dropout_p, training=self.training)\n",
    "        # 3. Полносвязный слой для классификации графа\n",
    "        h = self.classifier(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000 Avg Loss: 0.6498 Train Acc: 0.6533 Test Acc: 0.7105\n",
      "Epoch: 010 Avg Loss: 0.6019 Train Acc: 0.6667 Test Acc: 0.7105\n",
      "Epoch: 020 Avg Loss: 0.5662 Train Acc: 0.7200 Test Acc: 0.7895\n",
      "Epoch: 030 Avg Loss: 0.5588 Train Acc: 0.7067 Test Acc: 0.7895\n",
      "Epoch: 040 Avg Loss: 0.5410 Train Acc: 0.7200 Test Acc: 0.8421\n",
      "Epoch: 050 Avg Loss: 0.5351 Train Acc: 0.7600 Test Acc: 0.8158\n",
      "Epoch: 060 Avg Loss: 0.4531 Train Acc: 0.7800 Test Acc: 0.7895\n",
      "Epoch: 070 Avg Loss: 0.4882 Train Acc: 0.7600 Test Acc: 0.7368\n",
      "Epoch: 080 Avg Loss: 0.5115 Train Acc: 0.7600 Test Acc: 0.7368\n",
      "Epoch: 090 Avg Loss: 0.5188 Train Acc: 0.7533 Test Acc: 0.6842\n",
      "Epoch: 100 Avg Loss: 0.4796 Train Acc: 0.7933 Test Acc: 0.7368\n",
      "Epoch: 110 Avg Loss: 0.5166 Train Acc: 0.7533 Test Acc: 0.7895\n",
      "Epoch: 120 Avg Loss: 0.4981 Train Acc: 0.7467 Test Acc: 0.7368\n",
      "Epoch: 130 Avg Loss: 0.4815 Train Acc: 0.7733 Test Acc: 0.7105\n",
      "Epoch: 140 Avg Loss: 0.4757 Train Acc: 0.7467 Test Acc: 0.6842\n",
      "Epoch: 150 Avg Loss: 0.4666 Train Acc: 0.7800 Test Acc: 0.7368\n",
      "Epoch: 160 Avg Loss: 0.4782 Train Acc: 0.7933 Test Acc: 0.7105\n",
      "Epoch: 170 Avg Loss: 0.4812 Train Acc: 0.7667 Test Acc: 0.7632\n",
      "Epoch: 180 Avg Loss: 0.4952 Train Acc: 0.7533 Test Acc: 0.6842\n",
      "Epoch: 190 Avg Loss: 0.5301 Train Acc: 0.7867 Test Acc: 0.6842\n",
      "Epoch: 200 Avg Loss: 0.5355 Train Acc: 0.7600 Test Acc: 0.7105\n"
     ]
    }
   ],
   "source": [
    "model = GCN(\n",
    "    dataset.num_features, \n",
    "    n_hidden_layers=3, \n",
    "    n_hidden=64,\n",
    "    n_out=64, \n",
    "    n_classes=dataset.num_classes,\n",
    "    activation=torch.relu,\n",
    "    dropout_p=0.5\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=.01, weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(201):\n",
    "    epoch_losses = []\n",
    "    epoch_acc_train = 0\n",
    "    epoch_acc_test = 0\n",
    "    # train\n",
    "    model.train()\n",
    "    for step, data in enumerate(train_loader):  # Итерируемся по пакетам в обучающей выборке.\n",
    "        logits = model(data.x, data.edge_index, data.batch)  \n",
    "        loss = criterion(logits, data.y)\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_acc_train += (logits.argmax(dim=1) == data.y).sum().item()\n",
    "    epoch_acc_train /= len(train_loader.dataset)\n",
    "    model.eval()\n",
    "    # eval test\n",
    "    for data in test_loader:\n",
    "        logits = model(data.x, data.edge_index, data.batch)  \n",
    "        epoch_acc_test += (logits.argmax(dim=1) == data.y).sum().item()\n",
    "    epoch_acc_test /= len(test_loader.dataset)\n",
    "\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d} Avg Loss: {np.mean(epoch_losses):.4f} '\n",
    "              f'Train Acc: {epoch_acc_train:.4f} Test Acc: {epoch_acc_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b06e6ab994fc15ce23aa05c7ffef0f9130e5f92563bdff97ffc0fa050e903d35"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('gcn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
