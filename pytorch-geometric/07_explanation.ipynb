{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постоение объяснений работы модели при помощи PyG и Captum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решаем задачу классификации графов на примере датасета Mutagenicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# несколько удобных функций для описания датасетов\n",
    "def describe_dataset(dataset):\n",
    "    print(f'Dataset: {dataset}:')\n",
    "    print('======================')\n",
    "    print(f'Number of graphs: {len(dataset)}')\n",
    "    print(f'Number of features: {dataset.num_features}')\n",
    "    print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "def describe_graph(g):\n",
    "    print(g)\n",
    "    print('==============================================================')\n",
    "\n",
    "    # Gather some statistics about the graph.\n",
    "    print(f'Number of nodes: {g.num_nodes}')\n",
    "    print(f'Number of edges: {g.num_edges}')\n",
    "    print(f'Average node degree: {g.num_edges / g.num_nodes:.2f}')\n",
    "    if hasattr(g, 'train_mask'):\n",
    "        print(f'Number of training nodes: {g.train_mask.sum()}')\n",
    "        print(f'Training node label rate: {int(g.train_mask.sum()) / g.num_nodes:.2f}')\n",
    "    print(f'Has isolated nodes: {g.has_isolated_nodes()}')\n",
    "    print(f'Has self-loops: {g.has_self_loops()}')\n",
    "    print(f'Is undirected: {g.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\gcn\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/Mutagenicity.zip\n",
      "Extracting tmp\\mutag\\Mutagenicity\\Mutagenicity.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset('./tmp/mutag', name='Mutagenicity').shuffle()\n",
    "test_dataset = dataset[:len(dataset) // 10]\n",
    "train_dataset = dataset[len(dataset) // 10:]\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Mutagenicity(4337):\n",
      "======================\n",
      "Number of graphs: 4337\n",
      "Number of features: 14\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "describe_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_geometric.nn as gnn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        n_input: int, \n",
    "        n_hidden_layers: int, \n",
    "        n_hidden: int, \n",
    "        n_out: int,\n",
    "        n_classes: int,\n",
    "        dropout_p: float = 0.2,\n",
    "        activation: callable = F.relu\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout_p = dropout_p\n",
    "        self.activation = activation\n",
    "        # подход к построению глубоких GNN взят отсюда: \n",
    "        # https://github.com/dmlc/dgl/blob/master/examples/pytorch/graphsage/advanced/model.py\n",
    "        self.layers = nn.ModuleList()\n",
    "        # в качестве слоев используется gnn.GraphConv\n",
    "        # т.к. он может работать с весами на ребрах\n",
    "        if n_hidden_layers > 1:\n",
    "            self.layers.append(gnn.GraphConv(n_input, n_hidden))\n",
    "            for _ in range(1, n_hidden_layers-1):\n",
    "                self.layers.append(gnn.GraphConv(n_hidden, n_hidden))\n",
    "            self.layers.append(gnn.GraphConv(n_hidden, n_out))\n",
    "        else:\n",
    "            self.layers.append(gnn.GraphConv(n_input, n_out))\n",
    "        self.classifier = nn.Linear(n_out, n_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch, edge_weight=None):\n",
    "        # 1. Получение эмбеддингов узлов\n",
    "        h = x\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, edge_index, edge_weight)\n",
    "            h = self.activation(h)\n",
    "            h = F.dropout(h, p=self.dropout_p, training=self.training)\n",
    "        \n",
    "        # 2. Агрегация\n",
    "        h = gnn.global_add_pool(h, batch)\n",
    "        h = F.dropout(h, p=self.dropout_p, training=self.training)\n",
    "        # 3. Полносвязный слой для классификации графа\n",
    "        h = self.classifier(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (layers): ModuleList(\n",
      "    (0): GraphConv(14, 32)\n",
      "    (1): GraphConv(32, 32)\n",
      "    (2): GraphConv(32, 32)\n",
      "    (3): GraphConv(32, 32)\n",
      "    (4): GraphConv(32, 32)\n",
      "  )\n",
      "  (classifier): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "Epoch: 000 Avg Loss: 1.8125 Train Acc: 0.5051 Test Acc: 0.5104\n",
      "Epoch: 010 Avg Loss: 0.6121 Train Acc: 0.6657 Test Acc: 0.6721\n",
      "Epoch: 020 Avg Loss: 0.5876 Train Acc: 0.7003 Test Acc: 0.7275\n"
     ]
    }
   ],
   "source": [
    "model = GCN(\n",
    "    dataset.num_features, \n",
    "    n_hidden_layers=5, \n",
    "    n_hidden=32,\n",
    "    n_out=32, \n",
    "    n_classes=dataset.num_classes,\n",
    "    activation=torch.relu,\n",
    "    dropout_p=0.5\n",
    ")\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=.01, weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(31):\n",
    "    epoch_losses = []\n",
    "    epoch_acc_train = 0\n",
    "    epoch_acc_test = 0\n",
    "    # train\n",
    "    for step, data in enumerate(train_loader):  # Итерируемся по пакетам в обучающей выборке.\n",
    "        logits = model(data.x, data.edge_index, data.batch)  \n",
    "        loss = criterion(logits, data.y)\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_acc_train += (logits.argmax(dim=1) == data.y).sum().item()\n",
    "    epoch_acc_train /= len(train_loader.dataset)\n",
    "    # eval test\n",
    "    for data in test_loader:\n",
    "        logits = model(data.x, data.edge_index, data.batch)  \n",
    "        epoch_acc_test += (logits.argmax(dim=1) == data.y).sum().item()\n",
    "    epoch_acc_test /= len(test_loader.dataset)\n",
    "\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d} Avg Loss: {np.mean(epoch_losses):.4f} '\n",
    "              f'Train Acc: {epoch_acc_train:.4f} Test Acc: {epoch_acc_test:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует несколько подходов для объяснений предсказаний. \n",
    "\n",
    "### Saliency method \n",
    "Нужно рассчитать модуль градиента \n",
    "$$\n",
    "Attribution_{e_i} = |\\frac{\\partial F(x)}{\\partial w_{e_i}}|\n",
    "$$\n",
    "где $x$ - это входные данные, а $F(x)$ - результат работы модели на входе $x$\n",
    "\n",
    "### Integrated Gradients method\n",
    "Нужно рассчитать интеграл\n",
    "$$\n",
    "Attribution_{e_i} = \\int_{\\alpha =0}^1 \\frac{\\partial F(x_{\\alpha)}}{\\partial w_{e_i}} d\\alpha\n",
    "$$\n",
    "где $x_{\\alpha}$ - исходный граф, где веса всех ребер заменены на $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для расчета этих значений можно воспользоваться пакетом `captum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import Saliency, IntegratedGradients\n",
    "\n",
    "def model_forward(edge_mask, data):\n",
    "    # модель работает с пакетами, но в этой функции\n",
    "    # мы работаем с одним графом, поэтому фейкаем тензор\n",
    "    # batch\n",
    "    batch = torch.zeros(data.x.shape[0], dtype=int)\n",
    "    # edge_weight - это веса на ребрах\n",
    "    out = model(data.x, data.edge_index, batch, edge_mask)\n",
    "    return out\n",
    "\n",
    "def explain(data, target=0):\n",
    "    input_mask = torch.ones(data.edge_index.shape[1]).requires_grad_(True)\n",
    "    ig = IntegratedGradients(model_forward)\n",
    "    mask = ig.attribute(input_mask, target=target,\n",
    "                        additional_forward_args=(data,),\n",
    "                        internal_batch_size=data.edge_index.shape[1])\n",
    "    edge_mask = np.abs(mask.cpu().detach().numpy())\n",
    "    if edge_mask.max() > 0:  # avoid division by zero\n",
    "        edge_mask = edge_mask / edge_mask.max()\n",
    "    return edge_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.921472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.897662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.809852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.768895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.279283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.187710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.168890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.157605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.148718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.142195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.124114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.109585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.092984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.071138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.068110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.066999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.058414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.045355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0.039108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.025914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.022561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.016301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.011773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0.007651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     u   v  importance\n",
       "11   3   8    1.000000\n",
       "9    3   0    0.921472\n",
       "10   3   7    0.897662\n",
       "19   7   3    0.809852\n",
       "20   8   3    0.768895\n",
       "16   6   2    0.279283\n",
       "1    0   2    0.187710\n",
       "0    0   1    0.168890\n",
       "6    2   0    0.166630\n",
       "21   9   4    0.157605\n",
       "5    1   5    0.148718\n",
       "4    1   4    0.142195\n",
       "18   6  10    0.124114\n",
       "12   4   1    0.109585\n",
       "26  12   4    0.092984\n",
       "17   6   9    0.071138\n",
       "13   4   9    0.068110\n",
       "14   4  12    0.066999\n",
       "25  11   2    0.058414\n",
       "7    2   6    0.045355\n",
       "23   9  13    0.039108\n",
       "22   9   6    0.025914\n",
       "15   5   1    0.023926\n",
       "2    0   3    0.022561\n",
       "3    1   0    0.017726\n",
       "24  10   6    0.016301\n",
       "8    2  11    0.011773\n",
       "27  13   9    0.007651"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice\n",
    "import pandas as pd\n",
    "data = choice([t for t in test_dataset if not t.y.item()])\n",
    "edge_mask = explain(data, target=0)\n",
    "\n",
    "df = pd.DataFrame(zip(*data.edge_index.numpy(), edge_mask), columns=['u', 'v', 'importance'])\n",
    "df.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b06e6ab994fc15ce23aa05c7ffef0f9130e5f92563bdff97ffc0fa050e903d35"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('gcn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
