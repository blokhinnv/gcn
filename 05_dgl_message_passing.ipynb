{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "import dgl\r\n",
    "import dgl.function as fn"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Message passing framework:\r\n",
    "\r\n",
    "![](assets/img/05_dgl_message_passing_1.png) "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Реализуем GraphSage на DGL:\r\n",
    "\r\n",
    "![](assets/img/05_dgl_message_passing_2.png) "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class SAGEConv(nn.Module):\r\n",
    "    def __init__(self, n_inputs, n_outputs):\r\n",
    "        super().__init__()\r\n",
    "        self.linear = nn.Linear(2 * n_inputs, n_outputs)\r\n",
    "\r\n",
    "    def forward(self, G, h):\r\n",
    "        # G.local_scope() означает, что любые out-place изменения фичей узлов или ребер\r\n",
    "        # не будут видны за пределами контекста\r\n",
    "        # (inplace операции будут отражены за пределами контекста!)\r\n",
    "        with G.local_scope():\r\n",
    "            G.ndata['h'] = h\r\n",
    "            # 1 строка SAGE\r\n",
    "            # update_all делает описываемые операции для всех узлов/ребер\r\n",
    "            G.update_all(message_func=fn.copy_u('h', 'm'),  # фичи h -> сообщения m\r\n",
    "                         reduce_func=fn.mean('m', 'h_N')) # среднее по сообщениям m -> h_N\r\n",
    "            h_N = G.ndata['h_N']\r\n",
    "            # 2 строка SAGE\r\n",
    "            h_total = torch.cat([h, h_N], dim=1) \r\n",
    "            return self.linear(h_total)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Протестируем наш модуль (код взят из 03_dgl_node_classification; вместе `gnn.GraphConv` используем кастомный `SAGEConv`)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class GCN(nn.Module):\r\n",
    "    def __init__(self, n_input, n_hidden, n_output):\r\n",
    "        super().__init__()\r\n",
    "        self.conv1 = SAGEConv(n_input, n_hidden)\r\n",
    "        self.conv2 = SAGEConv(n_hidden, n_output)\r\n",
    "\r\n",
    "    def forward(self, G, in_features):\r\n",
    "        out = F.relu(self.conv1(G, in_features))\r\n",
    "        out = self.conv2(G, out)\r\n",
    "        return out\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from utils import train_cora_node_classification"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "dataset = dgl.data.CoraGraphDataset()\r\n",
    "G = dataset[0]\r\n",
    "\r\n",
    "n_input = G.ndata['feat'].shape[1]\r\n",
    "n_hidden = 16\r\n",
    "n_out = dataset.num_classes\r\n",
    "n_epochs = 100\r\n",
    "\r\n",
    "model = GCN(n_input, n_hidden, n_out)\r\n",
    "train_cora_node_classification(model, G)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "In epoch 0, loss: 1.949, val acc: 0.156 (best 0.156), test acc: 0.144 (best 0.144)\n",
      "In epoch 5, loss: 1.865, val acc: 0.286 (best 0.286), test acc: 0.283 (best 0.283)\n",
      "In epoch 10, loss: 1.713, val acc: 0.306 (best 0.332), test acc: 0.317 (best 0.338)\n",
      "In epoch 15, loss: 1.488, val acc: 0.436 (best 0.436), test acc: 0.405 (best 0.405)\n",
      "In epoch 20, loss: 1.208, val acc: 0.522 (best 0.522), test acc: 0.528 (best 0.528)\n",
      "In epoch 25, loss: 0.903, val acc: 0.626 (best 0.626), test acc: 0.609 (best 0.609)\n",
      "In epoch 30, loss: 0.616, val acc: 0.684 (best 0.684), test acc: 0.706 (best 0.706)\n",
      "In epoch 35, loss: 0.384, val acc: 0.758 (best 0.758), test acc: 0.762 (best 0.762)\n",
      "In epoch 40, loss: 0.228, val acc: 0.772 (best 0.774), test acc: 0.774 (best 0.772)\n",
      "In epoch 45, loss: 0.134, val acc: 0.770 (best 0.774), test acc: 0.774 (best 0.772)\n",
      "In epoch 50, loss: 0.082, val acc: 0.778 (best 0.778), test acc: 0.781 (best 0.781)\n",
      "In epoch 55, loss: 0.053, val acc: 0.780 (best 0.780), test acc: 0.776 (best 0.776)\n",
      "In epoch 60, loss: 0.036, val acc: 0.778 (best 0.780), test acc: 0.776 (best 0.776)\n",
      "In epoch 65, loss: 0.026, val acc: 0.780 (best 0.780), test acc: 0.777 (best 0.776)\n",
      "In epoch 70, loss: 0.020, val acc: 0.778 (best 0.780), test acc: 0.774 (best 0.776)\n",
      "In epoch 75, loss: 0.016, val acc: 0.778 (best 0.780), test acc: 0.774 (best 0.776)\n",
      "In epoch 80, loss: 0.014, val acc: 0.780 (best 0.780), test acc: 0.775 (best 0.776)\n",
      "In epoch 85, loss: 0.012, val acc: 0.778 (best 0.780), test acc: 0.773 (best 0.776)\n",
      "In epoch 90, loss: 0.011, val acc: 0.776 (best 0.780), test acc: 0.772 (best 0.776)\n",
      "In epoch 95, loss: 0.009, val acc: 0.776 (best 0.780), test acc: 0.772 (best 0.776)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "class WeightedSAGEConv(nn.Module):\r\n",
    "    def __init__(self, n_inputs, n_outputs):\r\n",
    "        super().__init__()\r\n",
    "        self.linear = nn.Linear(2 * n_inputs, n_outputs)\r\n",
    "\r\n",
    "    def forward(self, G, h):\r\n",
    "        # G.local_scope() означает, что любые out-place изменения фичей узлов или ребер\r\n",
    "        # не будут видны за пределами контекста\r\n",
    "        # (inplace операции будут отражены за пределами контекста!)\r\n",
    "        with G.local_scope():\r\n",
    "            G.ndata['h'] = h\r\n",
    "            G.edata['w'] = G.edata['weight']\r\n",
    "            # 1 строка SAGE\r\n",
    "            # update_all делает описываемые операции для всех узлов/ребер\r\n",
    "            G.update_all(message_func=fn.u_mul_e('h', 'w', 'm'),  # фичи h * веса входящих ребер w -> сообщения m\r\n",
    "                         reduce_func=fn.mean('m', 'h_N'))  # среднее по сообщениям m -> h_N\r\n",
    "\r\n",
    "            # мне не нравится, что так нет нормализации по весам\r\n",
    "            # # сумма весов входящих ребер\r\n",
    "            # G.update_all(fn.copy_e('w', 'm'), fn.sum('m', 'W'))\r\n",
    "            # # получение нормализованных весов\r\n",
    "            # # второй вариант эквивалентен первому\r\n",
    "            # # g.apply_edges(lambda edges: {'w1': edges.data['w'] / edges.dst['M']})\r\n",
    "            # G.apply_edges(fn.e_div_v('w', 'W', 'w_norm'))\r\n",
    "            # # усреднение по соседям с использованием нормализованных весов\r\n",
    "            # G.update_all(fn.u_mul_e('h', 'w_norm', 'm'), fn.sum('m', 'h_N'))\r\n",
    "            h_N = G.ndata['h_N']\r\n",
    "            # 2 строка SAGE\r\n",
    "            h_total = torch.cat([h, h_N], dim=1)\r\n",
    "            return self.linear(h_total)\r\n",
    "\r\n",
    "\r\n",
    "class GCN(nn.Module):\r\n",
    "    def __init__(self, n_input, n_hidden, n_output):\r\n",
    "        super().__init__()\r\n",
    "        self.conv1 = WeightedSAGEConv(n_input, n_hidden)\r\n",
    "        self.conv2 = WeightedSAGEConv(n_hidden, n_output)\r\n",
    "\r\n",
    "    def forward(self, G, in_features):\r\n",
    "        out = F.relu(self.conv1(G, in_features))\r\n",
    "        out = self.conv2(G, out)\r\n",
    "        return out\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "dataset = dgl.data.CoraGraphDataset()\r\n",
    "G = dataset[0]\r\n",
    "# добавили вес ребер\r\n",
    "G.edata['weight'] = torch.ones((G.num_edges(), 1))\r\n",
    "\r\n",
    "n_input = G.ndata['feat'].shape[1]\r\n",
    "n_hidden = 16\r\n",
    "n_out = dataset.num_classes\r\n",
    "n_epochs = 100\r\n",
    "\r\n",
    "\r\n",
    "model = GCN(n_input, n_hidden, n_out)\r\n",
    "train_cora_node_classification(model, G)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "In epoch 0, loss: 1.950, val acc: 0.122 (best 0.122), test acc: 0.130 (best 0.130)\n",
      "In epoch 5, loss: 1.873, val acc: 0.444 (best 0.444), test acc: 0.408 (best 0.408)\n",
      "In epoch 10, loss: 1.720, val acc: 0.438 (best 0.444), test acc: 0.419 (best 0.408)\n",
      "In epoch 15, loss: 1.490, val acc: 0.502 (best 0.502), test acc: 0.469 (best 0.469)\n",
      "In epoch 20, loss: 1.200, val acc: 0.568 (best 0.568), test acc: 0.527 (best 0.527)\n",
      "In epoch 25, loss: 0.890, val acc: 0.640 (best 0.640), test acc: 0.618 (best 0.618)\n",
      "In epoch 30, loss: 0.604, val acc: 0.718 (best 0.718), test acc: 0.707 (best 0.707)\n",
      "In epoch 35, loss: 0.377, val acc: 0.758 (best 0.758), test acc: 0.734 (best 0.734)\n",
      "In epoch 40, loss: 0.223, val acc: 0.758 (best 0.758), test acc: 0.757 (best 0.734)\n",
      "In epoch 45, loss: 0.130, val acc: 0.758 (best 0.758), test acc: 0.757 (best 0.734)\n",
      "In epoch 50, loss: 0.077, val acc: 0.756 (best 0.758), test acc: 0.756 (best 0.734)\n",
      "In epoch 55, loss: 0.049, val acc: 0.754 (best 0.758), test acc: 0.758 (best 0.734)\n",
      "In epoch 60, loss: 0.033, val acc: 0.758 (best 0.758), test acc: 0.760 (best 0.734)\n",
      "In epoch 65, loss: 0.024, val acc: 0.754 (best 0.758), test acc: 0.766 (best 0.734)\n",
      "In epoch 70, loss: 0.019, val acc: 0.752 (best 0.758), test acc: 0.770 (best 0.734)\n",
      "In epoch 75, loss: 0.015, val acc: 0.750 (best 0.758), test acc: 0.766 (best 0.734)\n",
      "In epoch 80, loss: 0.013, val acc: 0.750 (best 0.758), test acc: 0.768 (best 0.734)\n",
      "In epoch 85, loss: 0.011, val acc: 0.750 (best 0.758), test acc: 0.769 (best 0.734)\n",
      "In epoch 90, loss: 0.010, val acc: 0.750 (best 0.758), test acc: 0.765 (best 0.734)\n",
      "In epoch 95, loss: 0.009, val acc: 0.754 (best 0.758), test acc: 0.765 (best 0.734)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Пример усреднения фичей соседей с учетом нормализованны весов"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "g = dgl.graph(([0, 1, 2, 3,4], [1, 2, 3, 4,2]))\r\n",
    "g.ndata['x'] = torch.arange(g.num_nodes()*2).reshape(5, 2).float()\r\n",
    "g.edata['w'] = torch.arange(1, g.num_edges()+1).reshape(-1, 1).float()\r\n",
    "\r\n",
    "# сумма весов входящих ребер\r\n",
    "g.update_all(fn.copy_e('w', 'm'), fn.sum('m', 'W'))\r\n",
    "# получение нормализованных весов\r\n",
    "# второй вариант эквивалентен первому\r\n",
    "# g.apply_edges(lambda edges: {'w1': edges.data['w'] / edges.dst['M']})\r\n",
    "g.apply_edges(fn.e_div_v('w', 'W', 'w_norm'))\r\n",
    "# усреднение по соседям с использованием нормализованных весов\r\n",
    "g.update_all(fn.u_mul_e('x', 'w_norm', 'm'), fn.sum('m', 'h_N'))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('gcn': conda)"
  },
  "interpreter": {
   "hash": "a5d512aadeb6aaabeaf2234f39752bedcd0c0a511f474f5ce732b89a77e68aba"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}