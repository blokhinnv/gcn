{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "import dgl\r\n",
    "import dgl.function as fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message passing framework:\r\n",
    "\r\n",
    "![](assets/img/05_dgl_message_passing_1.png) \r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Три основных функции:\r\n",
    "1. `M` (message): принимает единственный аргумент `edges: EdgeBatch`, содержащий набор ребер (`DGL` неявно от нас разбивает граф на такие наборы). У `edges` есть 3 атрибута: `src` (фичи начальных узлов), `dst` (фичи конечных узлов) и `data` (фичи самих ребер)\r\n",
    "2. $\\sum$ (reduce):  принимает единственный аргумент `nodes: NodeBatch`, содержащий набор узлов. У `nodes` есть 1 атрибут `mailbox` для доступа к сообщениям, полученным от других узлов\r\n",
    "3. `U` (update): тоже принимает единственный аргумент `nodes: NodeBatch`. Эта функция оперирует с агрегатов из $\\sum$, обычно сочетая его с исходным представлением узла для генерации и сохранения нового представления\r\n",
    "\r\n",
    "`DGL` реализует необходимый минимум в message и reduce функций в модуле `dql.function`. Если этого не хватает, можно определить и собственные функции.\r\n",
    "\r\n",
    "Встроенные функции сообщений могут быть унарными или бинарными. Унарная функция - это `copy`; бинарные - `add`, `sub`, `mul`, `div` и `dot`. Далее в названиях идут буквы согласно соглашению: `u` - для `src` узлов; `v` для `dst` и `e` для `edges`.\r\n",
    "\r\n",
    "Встроенные функции свертки: `sum`, `max`, `min`, `mean`. \r\n",
    "\r\n",
    "\r\n",
    "Замечание: на практике наблюдаю, что стандартный обход соседей подразумевает входящие связи (in-neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn.u_add_v('hu', 'hv', 'he')\r\n",
    "def u_add_v(edges):\r\n",
    "    return {'he': edges.src['hu'] + edges.dst['hv']}\r\n",
    "\r\n",
    "# fn.sum('m', 'h')\r\n",
    "def sum_(nodes):\r\n",
    "    return {'h': nodes.mailbox['m'].sum(dim=1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если необходимо провести расчеты на ребрах без рассылки сообщений, то можно использовать метод `apply_edges`. \r\n",
    "\r\n",
    "```\r\n",
    "G.apply_edges(fn.u_add_v('el', 'er', 'e'))\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`update_all` - это верхнеуровневое API, объединяющее генерацию сообщений, агрегацию сообщений и обновление узлов. \r\n",
    "\r\n",
    "`update_all` может принимать 3 аргумента: функцию сообщения, функцию свертки и функцию обновления. \r\n",
    "\r\n",
    "В целях улучшения читаемости кода авторы рекомендуют не указывать функцию обновления здесь, а вызвать ее отдельно, т.к. обычно она состоит из простого присваивания и так легче понять, что происходит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\r\n",
    "# сообщение m: перемножить фичи ft начальных узлов и фичами a на ребрах\r\n",
    "# свертка: суммировать сообщения m и сохранить результат в .ndata['ft']\r\n",
    "G.update_all(fn.u_mul_e('ft', 'a', 'm'),\r\n",
    "                    fn.sum('m', 'ft'))\r\n",
    "# вызвать функцию обновления отдельно\r\n",
    "G.data['final_ft'] = G.ndata['ft'] * 2\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замечания по эффективности:\r\n",
    "1. Лучший вариант - использовать встроенные функции\r\n",
    "2. Обычно связей намного больше, чем узлов, так что чем меньше сообщений хранится на связях, тем лучше. \r\n",
    "\r\n",
    "Пример: вместо операции $W \\times (u||v)$ лучше использовать операции $W_l \\times u + W_r \\times v$, которые эквивалентны, но на ребрах не приходится хранить длинный вектор $(u||v)$\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если требуется обновить только часть узлов, следует создать подграф на основе этих узлов и применить `update_all` к нему.\r\n",
    "\r\n",
    "```\r\n",
    "nid = [0, 2, 3, 6, 7, 9]\r\n",
    "sg = g.subgraph(nid)\r\n",
    "sg.update_all(message_func, reduce_func)\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPF может быть применен и к гетерографам по следующему принципу:\r\n",
    "1. Для каждого отношения выполнить расчет сообщений и агрегацию\r\n",
    "2. Для каждого типа узла объединить результаты, полученные на различных отношениях\r\n",
    "\r\n",
    "`multi_update_all` принимает на вход словарь с параметрами для `update_all` на каждое отношение и \"cross type\" функцию свертки\r\n",
    "\r\n",
    "В случае гетерографа методу `apply_edges` можно передать тип ребер, для которых требуется выполнить вычисления:\r\n",
    "```\r\n",
    "G.apply_edges(fn.u_dot_v('h', 'h', 'score'), etype=etype)\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация GraphSage на DGL:\r\n",
    "\r\n",
    "![](assets/img/05_dgl_message_passing_2.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGEConv(nn.Module):\r\n",
    "    def __init__(self, n_inputs, n_outputs):\r\n",
    "        super().__init__()\r\n",
    "        self.linear = nn.Linear(2 * n_inputs, n_outputs)\r\n",
    "\r\n",
    "    def forward(self, G, h):\r\n",
    "        # G.local_scope() означает, что любые out-place изменения фичей узлов или ребер\r\n",
    "        # не будут видны за пределами контекста\r\n",
    "        # (inplace операции будут отражены за пределами контекста!)\r\n",
    "        with G.local_scope():\r\n",
    "            G.ndata['h'] = h\r\n",
    "            # 1 строка SAGE\r\n",
    "            # update_all делает описываемые операции для всех узлов/ребер\r\n",
    "            G.update_all(message_func=fn.copy_u('h', 'm'),  # фичи h -> сообщения m\r\n",
    "                         reduce_func=fn.mean('m', 'h_N')) # среднее по сообщениям m -> h_N\r\n",
    "            h_N = G.ndata['h_N']\r\n",
    "            # 2 строка SAGE\r\n",
    "            h_total = torch.cat([h, h_N], dim=1) \r\n",
    "            return self.linear(h_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем наш модуль (код взят из 03_dgl_node_classification; вместе `gnn.GraphConv` используем кастомный `SAGEConv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\r\n",
    "    def __init__(self, n_input, n_hidden, n_output):\r\n",
    "        super().__init__()\r\n",
    "        self.conv1 = SAGEConv(n_input, n_hidden)\r\n",
    "        self.conv2 = SAGEConv(n_hidden, n_output)\r\n",
    "\r\n",
    "    def forward(self, G, in_features):\r\n",
    "        out = F.relu(self.conv1(G, in_features))\r\n",
    "        out = self.conv2(G, out)\r\n",
    "        return out\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train_cora_node_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "In epoch 0, loss: 1.949, val acc: 0.156 (best 0.156), test acc: 0.144 (best 0.144)\n",
      "In epoch 5, loss: 1.865, val acc: 0.286 (best 0.286), test acc: 0.283 (best 0.283)\n",
      "In epoch 10, loss: 1.713, val acc: 0.306 (best 0.332), test acc: 0.317 (best 0.338)\n",
      "In epoch 15, loss: 1.488, val acc: 0.436 (best 0.436), test acc: 0.405 (best 0.405)\n",
      "In epoch 20, loss: 1.208, val acc: 0.522 (best 0.522), test acc: 0.528 (best 0.528)\n",
      "In epoch 25, loss: 0.903, val acc: 0.626 (best 0.626), test acc: 0.609 (best 0.609)\n",
      "In epoch 30, loss: 0.616, val acc: 0.684 (best 0.684), test acc: 0.706 (best 0.706)\n",
      "In epoch 35, loss: 0.384, val acc: 0.758 (best 0.758), test acc: 0.762 (best 0.762)\n",
      "In epoch 40, loss: 0.228, val acc: 0.772 (best 0.774), test acc: 0.774 (best 0.772)\n",
      "In epoch 45, loss: 0.134, val acc: 0.770 (best 0.774), test acc: 0.774 (best 0.772)\n",
      "In epoch 50, loss: 0.082, val acc: 0.778 (best 0.778), test acc: 0.781 (best 0.781)\n",
      "In epoch 55, loss: 0.053, val acc: 0.780 (best 0.780), test acc: 0.776 (best 0.776)\n",
      "In epoch 60, loss: 0.036, val acc: 0.778 (best 0.780), test acc: 0.776 (best 0.776)\n",
      "In epoch 65, loss: 0.026, val acc: 0.780 (best 0.780), test acc: 0.777 (best 0.776)\n",
      "In epoch 70, loss: 0.020, val acc: 0.778 (best 0.780), test acc: 0.774 (best 0.776)\n",
      "In epoch 75, loss: 0.016, val acc: 0.778 (best 0.780), test acc: 0.774 (best 0.776)\n",
      "In epoch 80, loss: 0.014, val acc: 0.780 (best 0.780), test acc: 0.775 (best 0.776)\n",
      "In epoch 85, loss: 0.012, val acc: 0.778 (best 0.780), test acc: 0.773 (best 0.776)\n",
      "In epoch 90, loss: 0.011, val acc: 0.776 (best 0.780), test acc: 0.772 (best 0.776)\n",
      "In epoch 95, loss: 0.009, val acc: 0.776 (best 0.780), test acc: 0.772 (best 0.776)\n"
     ]
    }
   ],
   "source": [
    "dataset = dgl.data.CoraGraphDataset()\r\n",
    "G = dataset[0]\r\n",
    "\r\n",
    "n_input = G.ndata['feat'].shape[1]\r\n",
    "n_hidden = 16\r\n",
    "n_out = dataset.num_classes\r\n",
    "n_epochs = 100\r\n",
    "\r\n",
    "model = GCN(n_input, n_hidden, n_out)\r\n",
    "train_cora_node_classification(model, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSAGEConv(nn.Module):\r\n",
    "    def __init__(self, n_inputs, n_outputs):\r\n",
    "        super().__init__()\r\n",
    "        self.linear = nn.Linear(2 * n_inputs, n_outputs)\r\n",
    "\r\n",
    "    def forward(self, G, h):\r\n",
    "        # G.local_scope() означает, что любые out-place изменения фичей узлов или ребер\r\n",
    "        # не будут видны за пределами контекста\r\n",
    "        # (inplace операции будут отражены за пределами контекста!)\r\n",
    "        with G.local_scope():\r\n",
    "            G.ndata['h'] = h\r\n",
    "            G.edata['w'] = G.edata['weight']\r\n",
    "            # 1 строка SAGE\r\n",
    "            # update_all делает описываемые операции для всех узлов/ребер\r\n",
    "            G.update_all(message_func=fn.u_mul_e('h', 'w', 'm'),  # фичи h * веса входящих ребер w -> сообщения m\r\n",
    "                         reduce_func=fn.mean('m', 'h_N'))  # среднее по сообщениям m -> h_N\r\n",
    "\r\n",
    "            # мне не нравится, что так нет нормализации по весам\r\n",
    "            # # сумма весов входящих ребер\r\n",
    "            # G.update_all(fn.copy_e('w', 'm'), fn.sum('m', 'W'))\r\n",
    "            # # получение нормализованных весов\r\n",
    "            # # второй вариант эквивалентен первому\r\n",
    "            # # g.apply_edges(lambda edges: {'w1': edges.data['w'] / edges.dst['M']})\r\n",
    "            # G.apply_edges(fn.e_div_v('w', 'W', 'w_norm'))\r\n",
    "            # # усреднение по соседям с использованием нормализованных весов\r\n",
    "            # G.update_all(fn.u_mul_e('h', 'w_norm', 'm'), fn.sum('m', 'h_N'))\r\n",
    "            # но вообще-то оно и без этого нормально работает\r\n",
    "            h_N = G.ndata['h_N']\r\n",
    "            # 2 строка SAGE\r\n",
    "            h_total = torch.cat([h, h_N], dim=1)\r\n",
    "            return self.linear(h_total)\r\n",
    "\r\n",
    "\r\n",
    "class GCN(nn.Module):\r\n",
    "    def __init__(self, n_input, n_hidden, n_output):\r\n",
    "        super().__init__()\r\n",
    "        self.conv1 = WeightedSAGEConv(n_input, n_hidden)\r\n",
    "        self.conv2 = WeightedSAGEConv(n_hidden, n_output)\r\n",
    "\r\n",
    "    def forward(self, G, in_features):\r\n",
    "        out = F.relu(self.conv1(G, in_features))\r\n",
    "        out = self.conv2(G, out)\r\n",
    "        return out\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "In epoch 0, loss: 1.950, val acc: 0.122 (best 0.122), test acc: 0.130 (best 0.130)\n",
      "In epoch 5, loss: 1.873, val acc: 0.444 (best 0.444), test acc: 0.408 (best 0.408)\n",
      "In epoch 10, loss: 1.720, val acc: 0.438 (best 0.444), test acc: 0.419 (best 0.408)\n",
      "In epoch 15, loss: 1.490, val acc: 0.502 (best 0.502), test acc: 0.469 (best 0.469)\n",
      "In epoch 20, loss: 1.200, val acc: 0.568 (best 0.568), test acc: 0.527 (best 0.527)\n",
      "In epoch 25, loss: 0.890, val acc: 0.640 (best 0.640), test acc: 0.618 (best 0.618)\n",
      "In epoch 30, loss: 0.604, val acc: 0.718 (best 0.718), test acc: 0.707 (best 0.707)\n",
      "In epoch 35, loss: 0.377, val acc: 0.758 (best 0.758), test acc: 0.734 (best 0.734)\n",
      "In epoch 40, loss: 0.223, val acc: 0.758 (best 0.758), test acc: 0.757 (best 0.734)\n",
      "In epoch 45, loss: 0.130, val acc: 0.758 (best 0.758), test acc: 0.757 (best 0.734)\n",
      "In epoch 50, loss: 0.077, val acc: 0.756 (best 0.758), test acc: 0.756 (best 0.734)\n",
      "In epoch 55, loss: 0.049, val acc: 0.754 (best 0.758), test acc: 0.758 (best 0.734)\n",
      "In epoch 60, loss: 0.033, val acc: 0.758 (best 0.758), test acc: 0.760 (best 0.734)\n",
      "In epoch 65, loss: 0.024, val acc: 0.754 (best 0.758), test acc: 0.766 (best 0.734)\n",
      "In epoch 70, loss: 0.019, val acc: 0.752 (best 0.758), test acc: 0.770 (best 0.734)\n",
      "In epoch 75, loss: 0.015, val acc: 0.750 (best 0.758), test acc: 0.766 (best 0.734)\n",
      "In epoch 80, loss: 0.013, val acc: 0.750 (best 0.758), test acc: 0.768 (best 0.734)\n",
      "In epoch 85, loss: 0.011, val acc: 0.750 (best 0.758), test acc: 0.769 (best 0.734)\n",
      "In epoch 90, loss: 0.010, val acc: 0.750 (best 0.758), test acc: 0.765 (best 0.734)\n",
      "In epoch 95, loss: 0.009, val acc: 0.754 (best 0.758), test acc: 0.765 (best 0.734)\n"
     ]
    }
   ],
   "source": [
    "dataset = dgl.data.CoraGraphDataset()\r\n",
    "G = dataset[0]\r\n",
    "# добавили вес ребер\r\n",
    "G.edata['weight'] = torch.ones((G.num_edges(), 1))\r\n",
    "\r\n",
    "n_input = G.ndata['feat'].shape[1]\r\n",
    "n_hidden = 16\r\n",
    "n_out = dataset.num_classes\r\n",
    "n_epochs = 100\r\n",
    "\r\n",
    "\r\n",
    "model = GCN(n_input, n_hidden, n_out)\r\n",
    "train_cora_node_classification(model, G)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример усреднения фичей соседей с учетом нормализованны весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.graph(([0, 1, 2, 3, 4], [1, 2, 3, 4, 2]))\r\n",
    "g.ndata['x'] = torch.arange(g.num_nodes()*2).reshape(5, 2).float()\r\n",
    "g.edata['w'] = torch.arange(1, g.num_edges()+1).reshape(-1, 1).float()\r\n",
    "\r\n",
    "# сумма весов входящих ребер\r\n",
    "g.update_all(fn.copy_e('w', 'm'), fn.sum('m', 'W'))\r\n",
    "# получение нормализованных весов\r\n",
    "# второй вариант эквивалентен первому\r\n",
    "# g.apply_edges(lambda edges: {'w1': edges.data['w'] / edges.dst['M']})\r\n",
    "g.apply_edges(fn.e_div_v('w', 'W', 'w_norm'))\r\n",
    "# усреднение по соседям с использованием нормализованных весов\r\n",
    "g.update_all(fn.u_mul_e('x', 'w_norm', 'm'), fn.sum('m', 'h_N'))\r\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b06e6ab994fc15ce23aa05c7ffef0f9130e5f92563bdff97ffc0fa050e903d35"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('gcn': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}