{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgl\n",
    "import dgl.data\n",
    "import dgl.nn as gnn\n",
    "\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Постановка задачи и ход решения\n",
    "\n",
    "Задача: предсказать какую-нибудь характеристику на уровне целого графа\n",
    "\n",
    "Типичный датасет:\n",
    "* содержит некоторое кол-во графов\n",
    "* у каждого графа есть фичи на узлах и метка на весь граф \n",
    "\n",
    "Для примера используем синтетический датасет GIN. \n",
    "\n",
    "План:\n",
    "1. Подготовить батч графов\n",
    "2. Прогнать батч через сеть и получить представления узлов в батче\n",
    "3. Получить представление графов в батче\n",
    "4. Классификация графов в батча\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение датасета на батчи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема: нужно уметь разбивать датасет на мини-батчи. \n",
    "\n",
    "Объединенный граф (батч-граф) состоит из нескольких графов, объединенных в один в виде несвязных компонент. Фичи узлов и ребер сохраняются. Это такой же граф, как и обычный `DGLGraph`, но содержит доп. информацию для восстановления исходных графов. Развернуть графы назад можно с помощью метода `unbatch`.\n",
    "\n",
    "Примечание: большинство операций на батч-графом сотрут информацию о структуре батча.\n",
    "\n",
    "![](./assets/img/07_dgl_graph_classification_batch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch=Graph(num_nodes=7, num_edges=7,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n",
      "batch.batch_size=2\n",
      "batch.batch_num_nodes()=tensor([4, 3])\n",
      "batch.batch_num_edges()=tensor([3, 4])\n"
     ]
    }
   ],
   "source": [
    "G1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))\n",
    "G2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))\n",
    "\n",
    "batch = dgl.batch([G1, G2])\n",
    "print(f'{batch=}')\n",
    "print(f'{batch.batch_size=}')\n",
    "print(f'{batch.batch_num_nodes()=}')\n",
    "print(f'{batch.batch_num_edges()=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow:\n",
    "1. Создаем как обычно двухслойную сеть. На вход придет батч-граф. \n",
    "2. Дальше нужно сагрегировать представления узлов (и возможно ребер) чтобы получить представление графа в целом (самый простой вариант - усреднить с помощью `dgl.mean_nodes()` или суммировать с помощью `dgl.readout_nodes()`). Этот процесс называют `readout`. `DGL` предоставляет набор функций, которые могут работать с батч-графами и получать для них представление. \n",
    "\n",
    "![](./assets/img/07_dgl_graph_classification_graph_classifier.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgl.readout_nodes(G1, \"h\")=tensor([[4., 6.]])\n",
      "dgl.readout_nodes(G2, \"h\")=tensor([[21., 24.]])\n",
      "dgl.readout_nodes(batch, \"h\")=tensor([[ 4.,  6.],\n",
      "        [21., 24.]])\n"
     ]
    }
   ],
   "source": [
    "G1 = dgl.graph(([0, 1], [1, 0]))\n",
    "G1.ndata['h'] = torch.tensor([[1, 2], [3, 4]]).float()\n",
    "G2 = dgl.graph(([0, 1], [1, 2]))\n",
    "G2.ndata['h'] = torch.tensor([[5, 6], [7, 8], [9, 10]]).float()\n",
    "\n",
    "batch = dgl.batch([G1, G2])\n",
    "\n",
    "print(f'{dgl.readout_nodes(G1, \"h\")=}')\n",
    "print(f'{dgl.readout_nodes(G2, \"h\")=}')\n",
    "print(f'{dgl.readout_nodes(batch, \"h\")=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение датасета на батчи с помощью `GraphDataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что разбить датасет из графов на батчи, используем `GraphDataLoader`, который работает со стандартными сэмплерами из `torch`.\n",
    "\n",
    "Каждый элемент в датасете представляет собой пару (граф, метка). `GraphDataLoader` при итерации по нему возвращает два объекта: объедененный граф для батча и вектор с метками для каждого графа из батча. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dgl.data.GINDataset('PROTEINS', self_loop=True)\n",
    "print('Node feature dimensionality:', dataset.dim_nfeats)\n",
    "print('Number of graph categories:', dataset.gclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = len(dataset)\n",
    "num_train = int(num_examples * .8)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(torch.arange(num_train))\n",
    "test_sampler = SubsetRandomSampler(torch.arange(num_train, num_examples))\n",
    "\n",
    "train_dataloader = GraphDataLoader(dataset, sampler=train_sampler, batch_size=5, drop_last=False)\n",
    "test_dataloader = GraphDataLoader(dataset, sampler=test_sampler, batch_size=5, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_dataloader)\n",
    "batched_graph, labels = next(it)\n",
    "print('Кол-во узлов в каждом графе из батча:', batched_graph.batch_num_nodes())\n",
    "print('Кол-во ребер в каждом графе из батча:', batched_graph.batch_num_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получить исходные графы из минибатча\n",
    "graphs = dgl.unbatch(batched_graph)\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = gnn.GraphConv(n_inputs, n_hidden)\n",
    "        self.conv2 = gnn.GraphConv(n_hidden, n_hidden)\n",
    "        self.linear = nn.Linear(n_hidden, num_classes)\n",
    "\n",
    "    def forward(self, G, features):\n",
    "        out = F.relu(self.conv1(G, features))\n",
    "        out = F.relu(self.conv2(G, out))\n",
    "        with G.local_scope():\n",
    "            G.ndata['h'] = out\n",
    "            out = dgl.mean_nodes(G, 'h')\n",
    "            out = self.linear(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.32286995515695066\n"
     ]
    }
   ],
   "source": [
    "n_inputs, n_hidden, n_out = dataset.dim_nfeats, 16, dataset.gclasses\n",
    "model = GCN(n_inputs, n_hidden, n_out)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['attr'].float())\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['attr'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy:', num_correct / num_tests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для случая гетерографов нужно:\n",
    "1. Использовать модели, работающие с гетерографами\n",
    "2. Изменить readout: сначала, например, усредняем по типам узлов; потом - суммируем средние.\n",
    "\n",
    "```\n",
    "hg = 0\n",
    "for ntype in g.ntypes:\n",
    "    hg = hg + dgl.mean_nodes(g, 'h', ntype=ntype)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b06e6ab994fc15ce23aa05c7ffef0f9130e5f92563bdff97ffc0fa050e903d35"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('gcn': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
