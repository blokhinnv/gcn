{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import dgl\r\n",
    "import dgl.nn as gnn\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "import networkx as nx"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stochastic Training\r\n",
    "\r\n",
    "В ситуации, когда имеется большой граф, очень легко выйти за пределы имеющейся памяти. Потенциальное решение: обучение на основе минибатчей."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Frontier, MFG, block\r\n",
    "\r\n",
    "Для каждого шага градиентного спуска выбирается минибатч из узлов, финальные скрытые представления которых после `L` слоя сети должны быть рассчитаны. После этого на `L-1` слое рассматриваются все (или некоторые) их соседи. Эта процедура повторяется, пока мы не достигнем первого слоя сети.\r\n",
    "\r\n",
    "Такая процедура позволяет построить граф зависимостей, необходимый для расчетов (иногда это называют графом вычислений; в `DGL` используется термин message flow graphs (MFGs))\r\n",
    "\r\n",
    "![](./assets/img/10_dgl_stochastic_deps.png)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "src = torch.tensor([0,1,1,2,3 ])\r\n",
    "dst = torch.tensor([3,0,2,3,4 ])\r\n",
    "G = dgl.graph((src, dst))\r\n",
    "G.ndata['feat'] = torch.randn((G.num_nodes(), 5))\r\n",
    "nx.draw(dgl.to_networkx(G), with_labels=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"302.4pt\" version=\"1.1\" viewBox=\"0 0 446.4 302.4\" width=\"446.4pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-08-07T13:53:20.497109</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.1, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 302.4 \r\nL 446.4 302.4 \r\nL 446.4 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path clip-path=\"url(#pcad776ad3d)\" d=\"M 393.888425 266.499202 \r\nQ 302.149946 223.009303 211.421727 179.998333 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\r\n    <path clip-path=\"url(#pcad776ad3d)\" d=\"M 214.179414 183.519009 \r\nL 211.421727 179.998333 \r\nL 215.89288 179.904589 \r\nL 214.179414 183.519009 \r\nz\r\n\" style=\"stroke:#000000;stroke-linecap:round;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path clip-path=\"url(#pcad776ad3d)\" d=\"M 387.406041 136.749448 \r\nQ 394.097519 199.171828 400.669831 260.482543 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\r\n    <path clip-path=\"url(#pcad776ad3d)\" d=\"M 402.232093 256.292157 \r\nL 400.669831 260.482543 \r\nL 398.254879 256.718501 \r\nL 402.232093 256.292157 \r\nz\r\n\" style=\"stroke:#000000;stroke-linecap:round;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path clip-path=\"url(#pcad776ad3d)\" d=\"M 378.880719 123.984659 \r\nQ 317.01948 90.216064 256.139585 56.98316 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\r\n    <path clip-path=\"url(#pcad776ad3d)\" d=\"M 258.692269 60.65519 \r\nL 256.139585 56.98316 \r\nL 260.608819 57.14423 \r\nL 258.692269 60.65519 \r\nz\r\n\" style=\"stroke:#000000;stroke-linecap:round;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path clip-path=\"url(#pcad776ad3d)\" d=\"M 244.592622 60.435251 \r\nQ 225.070356 114.053876 205.930596 166.621935 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\r\n    <path clip-path=\"url(#pcad776ad3d)\" d=\"M 209.1784 163.547562 \r\nL 205.930596 166.621935 \r\nL 205.41978 162.179068 \r\nL 209.1784 163.547562 \r\nz\r\n\" style=\"stroke:#000000;stroke-linecap:round;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path clip-path=\"url(#pcad776ad3d)\" d=\"M 196.17908 169.982376 \r\nQ 123.636031 104.000095 51.920067 38.770097 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\r\n    <path clip-path=\"url(#pcad776ad3d)\" d=\"M 53.53341 42.941083 \r\nL 51.920067 38.770097 \r\nL 56.224861 39.982015 \r\nL 53.53341 42.941083 \r\nz\r\n\" style=\"stroke:#000000;stroke-linecap:round;\"/>\r\n   </g>\r\n   <g id=\"PathCollection_1\">\r\n    <defs>\r\n     <path d=\"M 0 8.660254 \r\nC 2.296726 8.660254 4.499694 7.747755 6.123724 6.123724 \r\nC 7.747755 4.499694 8.660254 2.296726 8.660254 0 \r\nC 8.660254 -2.296726 7.747755 -4.499694 6.123724 -6.123724 \r\nC 4.499694 -7.747755 2.296726 -8.660254 0 -8.660254 \r\nC -2.296726 -8.660254 -4.499694 -7.747755 -6.123724 -6.123724 \r\nC -7.747755 -4.499694 -8.660254 -2.296726 -8.660254 0 \r\nC -8.660254 2.296726 -7.747755 4.499694 -6.123724 6.123724 \r\nC -4.499694 7.747755 -2.296726 8.660254 0 8.660254 \r\nz\r\n\" id=\"m30b9603576\" style=\"stroke:#1f78b4;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#pcad776ad3d)\">\r\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"401.712397\" xlink:href=\"#m30b9603576\" y=\"270.208264\"/>\r\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"386.482525\" xlink:href=\"#m30b9603576\" y=\"128.134307\"/>\r\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"247.555587\" xlink:href=\"#m30b9603576\" y=\"52.297358\"/>\r\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"202.58549\" xlink:href=\"#m30b9603576\" y=\"175.809392\"/>\r\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"44.687603\" xlink:href=\"#m30b9603576\" y=\"32.191736\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"text_1\">\r\n    <g clip-path=\"url(#pcad776ad3d)\">\r\n     <!-- 0 -->\r\n     <g transform=\"translate(397.894897 273.519514)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 2034 4250 \r\nQ 1547 4250 1301 3770 \r\nQ 1056 3291 1056 2328 \r\nQ 1056 1369 1301 889 \r\nQ 1547 409 2034 409 \r\nQ 2525 409 2770 889 \r\nQ 3016 1369 3016 2328 \r\nQ 3016 3291 2770 3770 \r\nQ 2525 4250 2034 4250 \r\nz\r\nM 2034 4750 \r\nQ 2819 4750 3233 4129 \r\nQ 3647 3509 3647 2328 \r\nQ 3647 1150 3233 529 \r\nQ 2819 -91 2034 -91 \r\nQ 1250 -91 836 529 \r\nQ 422 1150 422 2328 \r\nQ 422 3509 836 4129 \r\nQ 1250 4750 2034 4750 \r\nz\r\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-30\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"text_2\">\r\n    <g clip-path=\"url(#pcad776ad3d)\">\r\n     <!-- 1 -->\r\n     <g transform=\"translate(382.665025 131.445557)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 794 531 \r\nL 1825 531 \r\nL 1825 4091 \r\nL 703 3866 \r\nL 703 4441 \r\nL 1819 4666 \r\nL 2450 4666 \r\nL 2450 531 \r\nL 3481 531 \r\nL 3481 0 \r\nL 794 0 \r\nL 794 531 \r\nz\r\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-31\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"text_3\">\r\n    <g clip-path=\"url(#pcad776ad3d)\">\r\n     <!-- 2 -->\r\n     <g transform=\"translate(243.738087 55.608608)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 1228 531 \r\nL 3431 531 \r\nL 3431 0 \r\nL 469 0 \r\nL 469 531 \r\nQ 828 903 1448 1529 \r\nQ 2069 2156 2228 2338 \r\nQ 2531 2678 2651 2914 \r\nQ 2772 3150 2772 3378 \r\nQ 2772 3750 2511 3984 \r\nQ 2250 4219 1831 4219 \r\nQ 1534 4219 1204 4116 \r\nQ 875 4013 500 3803 \r\nL 500 4441 \r\nQ 881 4594 1212 4672 \r\nQ 1544 4750 1819 4750 \r\nQ 2544 4750 2975 4387 \r\nQ 3406 4025 3406 3419 \r\nQ 3406 3131 3298 2873 \r\nQ 3191 2616 2906 2266 \r\nQ 2828 2175 2409 1742 \r\nQ 1991 1309 1228 531 \r\nz\r\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-32\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"text_4\">\r\n    <g clip-path=\"url(#pcad776ad3d)\">\r\n     <!-- 3 -->\r\n     <g transform=\"translate(198.76799 179.120642)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 2597 2516 \r\nQ 3050 2419 3304 2112 \r\nQ 3559 1806 3559 1356 \r\nQ 3559 666 3084 287 \r\nQ 2609 -91 1734 -91 \r\nQ 1441 -91 1130 -33 \r\nQ 819 25 488 141 \r\nL 488 750 \r\nQ 750 597 1062 519 \r\nQ 1375 441 1716 441 \r\nQ 2309 441 2620 675 \r\nQ 2931 909 2931 1356 \r\nQ 2931 1769 2642 2001 \r\nQ 2353 2234 1838 2234 \r\nL 1294 2234 \r\nL 1294 2753 \r\nL 1863 2753 \r\nQ 2328 2753 2575 2939 \r\nQ 2822 3125 2822 3475 \r\nQ 2822 3834 2567 4026 \r\nQ 2313 4219 1838 4219 \r\nQ 1578 4219 1281 4162 \r\nQ 984 4106 628 3988 \r\nL 628 4550 \r\nQ 988 4650 1302 4700 \r\nQ 1616 4750 1894 4750 \r\nQ 2613 4750 3031 4423 \r\nQ 3450 4097 3450 3541 \r\nQ 3450 3153 3228 2886 \r\nQ 3006 2619 2597 2516 \r\nz\r\n\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-33\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"text_5\">\r\n    <g clip-path=\"url(#pcad776ad3d)\">\r\n     <!-- 4 -->\r\n     <g transform=\"translate(40.870103 35.502986)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 2419 4116 \r\nL 825 1625 \r\nL 2419 1625 \r\nL 2419 4116 \r\nz\r\nM 2253 4666 \r\nL 3047 4666 \r\nL 3047 1625 \r\nL 3713 1625 \r\nL 3713 1100 \r\nL 3047 1100 \r\nL 3047 0 \r\nL 2419 0 \r\nL 2419 1100 \r\nL 313 1100 \r\nL 313 1709 \r\nL 2253 4666 \r\nz\r\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-34\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pcad776ad3d\">\r\n   <rect height=\"288\" width=\"432\" x=\"7.2\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Допустим, мы планируем создать сеть с `L=2` слоями и нас интересует представление только узла `4`.\r\n",
    "\r\n",
    "Для расчета представления узла `4` на `l=2` слое, нужно получить представления узла `3`: $m_4^{2} = M(\\{h_3^{1}\\})$\r\n",
    "\r\n",
    "Frontier (фронт (как в BFS?)) второго слоя сети - это граф, который содержит все узлы оригинального графа, но только те ребра, которые необходимы для передаче сообщений выходным узлам (в этом примере - узлу 4). \r\n",
    "\r\n",
    "Для получения фронта можно воспользоваться функцией `dgl.in_subgraph`, которая порождает подграф, содержащий все узлы исходного графа, и только те ребра, которые входят в узлы из заданного множества. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "frontier = dgl.in_subgraph(G, [4])\r\n",
    "print(frontier.all_edges())\r\n",
    "print(frontier.num_nodes())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(tensor([3]), tensor([4]))\n",
      "5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проблема в том, что выполнять рассылку сообщений на этом графе нельзя, т.к. он содержит все узлы из исходного графа, а нам нужны только узлы 3 и 4 (как вход слоя) и узел 4 (как выход слоя).\r\n",
    "\r\n",
    "Авторы `DGL` конструируют на основе этих узлов двудольный граф, где узлы делятся на 2 типа: входные и выходные (их кол-во отличается). Такой двудольный граф авторы называются message flow graph.\r\n",
    "\r\n",
    "Множество выходных узлов всегда является подмножеством входных узлов, т.к. для расчета представления выходных узлов следующего слоя требуются их представления с предыдущего слоя.\r\n",
    "\r\n",
    "Технически любой подграф, содержащий все узлы, может называться фронтом, но при создании MFG `DGL` проверяет, что множество целевых узлов покрывает множество конечных узлов имеющихся в подграфе ребер."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для превращения фронта в MFG `DGL` предоставляет функцию `dgl.to_block`.\r\n",
    "\r\n",
    "У MFG (block) есть несколько специфичных атрибутов:\r\n",
    "* `.srcnodes` для обращения к входным узлам (аналогично `.nodes` у обычных графов)\r\n",
    "* `.srcdata` для обращения к фичам входных узлов (аналогично `.ndata` у обычных графов)\r\n",
    "* `.dstnodes` для обращения к выходным узлам\r\n",
    "* `.dstdata` для обращения к фичам выходных узлов"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "dst_nodes = torch.LongTensor([4])\r\n",
    "block = dgl.to_block(frontier, dst_nodes)\r\n",
    "print(f'{block.number_of_src_nodes()=}')\r\n",
    "print(f'{block.number_of_dst_nodes()=}')\r\n",
    "print(f'{block.srcdata[dgl.NID]=}') # выходные узлы всегда будут находиться в начале\r\n",
    "print(f'{block.dstdata[dgl.NID]=}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "block.number_of_src_nodes()=2\n",
      "block.number_of_dst_nodes()=1\n",
      "block.srcdata[dgl.NID]=tensor([4, 3])\n",
      "block.dstdata[dgl.NID]=tensor([4])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neighborhood sampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Построение MFG - настраиваемый процесс, в который можно вносить модификации. Например, в целях ускорения обучения иногда удобно рассматривать не всех соседей, а некоторое их подножество. `DGL` предоставляет инструменты для манипулирования процессом сэмплинга соседей.\r\n",
    "\r\n",
    "В `DGL` есть несколько классов (сэмплеров), которые генерируют граф зависимостей для каждого из слоев в зависимости от узлов, для которых мы хотим провести расчеты.\r\n",
    "\r\n",
    "Простейший вариант - `MultiLayerFullNeighborSampler`, который подразумевает, что узел получает сообщения от всех своих соседей."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "src = torch.randint(0, 100, (500, ))\r\n",
    "dst = torch.randint(0, 100, (500, ))\r\n",
    "\r\n",
    "train_ids = torch.randint(0, 100, (30,))\r\n",
    "\r\n",
    "G = dgl.graph((src, dst))\r\n",
    "G"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Graph(num_nodes=100, num_edges=500,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Допустим, у нас есть набор узлов `train_ids` для обучения. Нам нужно разбить его на батчи и создать для каждого батча MFG.\r\n",
    "\r\n",
    "Для этого мы сначала создаем нужный сэмплер. Затем на его основе создаем dataloader. Итерируясь по этому dataloader'у, мы получаем набор специальным образом сгенерированных графов, отражающих зависимости на каждом из слоев."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "sampler = dgl.dataloading.MultiLayerFullNeighborSampler(n_layers=2)\r\n",
    "dataloader = dgl.dataloading.NodeDataLoader(G, train_ids, sampler,\r\n",
    "                                            batch_size=5, shuffle=True,\r\n",
    "                                            drop_last=False, num_workers=4)\r\n",
    "\r\n",
    "input_nodes, output_nodes, blocks = next(iter(dataloader))                                          "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Block(num_src_nodes=81, num_dst_nodes=32, num_edges=155), Block(num_src_nodes=32, num_dst_nodes=5, num_edges=34)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# input_nodes - набор узлов, необходимый для вычисления представлений узлов \r\n",
    "# из output_nodes\r\n",
    "print(input_nodes)\r\n",
    "print('требуются для вычислений по узлам:')\r\n",
    "print(output_nodes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([84, 80, 29, 54, 37, 68, 43, 66, 99, 72,  4, 20, 25, 70, 90, 61, 27, 28,\n",
      "        49, 26, 15, 65, 46, 95, 35, 71, 75, 64, 48, 78, 69, 13, 83, 32, 59, 89,\n",
      "         1, 11,  3, 44, 39, 45, 21, 19, 77, 51, 33,  5, 67, 10, 52, 56, 58, 23,\n",
      "        22,  7, 16, 55, 40, 12, 91, 81, 36, 86, 31, 85, 82, 93, 63, 87, 79, 14,\n",
      "         0, 47, 97, 60, 73,  2, 57,  9, 18])\n",
      "требуются для вычислений по узлам:\n",
      "tensor([84, 80, 29, 54, 37])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# blocks содержат для каждого слоя описания того, представления каких узлов\r\n",
    "# будут рассчитаны на выходе, представления каких узлов нужны на входе\r\n",
    "# и как представления от входов распространяются к выходу\r\n",
    "blocks"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Block(num_src_nodes=81, num_dst_nodes=32, num_edges=155),\n",
       " Block(num_src_nodes=32, num_dst_nodes=5, num_edges=34)]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# простой пример графа\r\n",
    "src = torch.tensor([0,1,1,2,3 ])\r\n",
    "dst = torch.tensor([3,0,2,3,4 ])\r\n",
    "G = dgl.graph((src, dst))\r\n",
    "G.ndata['feat'] = torch.randn((G.num_nodes(), 5))\r\n",
    "nx.draw(dgl.to_networkx(G), with_labels=True)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"302.4pt\" version=\"1.1\" viewBox=\"0 0 446.4 302.4\" width=\"446.4pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-08-07T14:27:34.969666</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.1, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 302.4 \r\nL 446.4 302.4 \r\nL 446.4 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path clip-path=\"url(#pb49fd601a8)\" d=\"M 393.074262 158.180833 \r\nQ 268.886117 148.841605 145.812857 139.586219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\r\n    <path clip-path=\"url(#pb49fd601a8)\" d=\"M 149.651613 141.880549 \r\nL 145.812857 139.586219 \r\nL 149.951575 137.891812 \r\nL 149.651613 141.880549 \r\nz\r\n\" style=\"stroke:#000000;stroke-linecap:round;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path clip-path=\"url(#pb49fd601a8)\" d=\"M 323.490977 237.369855 \r\nQ 359.544969 201.169292 394.809997 165.7609 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\r\n    <path clip-path=\"url(#pb49fd601a8)\" d=\"M 390.570234 167.183717 \r\nL 394.809997 165.7609 \r\nL 393.404393 170.006401 \r\nL 390.570234 167.183717 \r\nz\r\n\" style=\"stroke:#000000;stroke-linecap:round;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path clip-path=\"url(#pb49fd601a8)\" d=\"M 308.761228 244.35094 \r\nQ 181.033906 256.85763 54.419296 269.255365 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\r\n    <path clip-path=\"url(#pb49fd601a8)\" d=\"M 58.595159 270.856042 \r\nL 54.419296 269.255365 \r\nL 58.205355 266.87508 \r\nL 58.595159 270.856042 \r\nz\r\n\" style=\"stroke:#000000;stroke-linecap:round;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path clip-path=\"url(#pb49fd601a8)\" d=\"M 49.631461 263.100919 \r\nQ 90.372213 204.53156 130.474529 146.880024 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\r\n    <path clip-path=\"url(#pb49fd601a8)\" d=\"M 126.548539 149.021658 \r\nL 130.474529 146.880024 \r\nL 129.832242 151.305797 \r\nL 126.548539 149.021658 \r\nz\r\n\" style=\"stroke:#000000;stroke-linecap:round;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path clip-path=\"url(#pb49fd601a8)\" d=\"M 143.866021 135.104488 \r\nQ 247.148764 85.522293 349.4236 36.423958 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\r\n    <path clip-path=\"url(#pb49fd601a8)\" d=\"M 344.952042 36.352064 \r\nL 349.4236 36.423958 \r\nL 346.68315 39.958068 \r\nL 344.952042 36.352064 \r\nz\r\n\" style=\"stroke:#000000;stroke-linecap:round;\"/>\r\n   </g>\r\n   <g id=\"PathCollection_1\">\r\n    <defs>\r\n     <path d=\"M 0 8.660254 \r\nC 2.296726 8.660254 4.499694 7.747755 6.123724 6.123724 \r\nC 7.747755 4.499694 8.660254 2.296726 8.660254 0 \r\nC 8.660254 -2.296726 7.747755 -4.499694 6.123724 -6.123724 \r\nC 4.499694 -7.747755 2.296726 -8.660254 0 -8.660254 \r\nC -2.296726 -8.660254 -4.499694 -7.747755 -6.123724 -6.123724 \r\nC -7.747755 -4.499694 -8.660254 -2.296726 -8.660254 0 \r\nC -8.660254 2.296726 -7.747755 4.499694 -6.123724 6.123724 \r\nC -4.499694 7.747755 -2.296726 8.660254 0 8.660254 \r\nz\r\n\" id=\"mf48714cc8d\" style=\"stroke:#1f78b4;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#pb49fd601a8)\">\r\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"401.712397\" xlink:href=\"#mf48714cc8d\" y=\"158.83044\"/>\r\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"317.378521\" xlink:href=\"#mf48714cc8d\" y=\"243.50716\"/>\r\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"44.687603\" xlink:href=\"#mf48714cc8d\" y=\"270.208264\"/>\r\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"136.058352\" xlink:href=\"#mf48714cc8d\" y=\"138.852658\"/>\r\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"358.239578\" xlink:href=\"#mf48714cc8d\" y=\"32.191736\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"text_1\">\r\n    <g clip-path=\"url(#pb49fd601a8)\">\r\n     <!-- 0 -->\r\n     <g transform=\"translate(397.894897 162.14169)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 2034 4250 \r\nQ 1547 4250 1301 3770 \r\nQ 1056 3291 1056 2328 \r\nQ 1056 1369 1301 889 \r\nQ 1547 409 2034 409 \r\nQ 2525 409 2770 889 \r\nQ 3016 1369 3016 2328 \r\nQ 3016 3291 2770 3770 \r\nQ 2525 4250 2034 4250 \r\nz\r\nM 2034 4750 \r\nQ 2819 4750 3233 4129 \r\nQ 3647 3509 3647 2328 \r\nQ 3647 1150 3233 529 \r\nQ 2819 -91 2034 -91 \r\nQ 1250 -91 836 529 \r\nQ 422 1150 422 2328 \r\nQ 422 3509 836 4129 \r\nQ 1250 4750 2034 4750 \r\nz\r\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-30\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"text_2\">\r\n    <g clip-path=\"url(#pb49fd601a8)\">\r\n     <!-- 1 -->\r\n     <g transform=\"translate(313.561021 246.81841)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 794 531 \r\nL 1825 531 \r\nL 1825 4091 \r\nL 703 3866 \r\nL 703 4441 \r\nL 1819 4666 \r\nL 2450 4666 \r\nL 2450 531 \r\nL 3481 531 \r\nL 3481 0 \r\nL 794 0 \r\nL 794 531 \r\nz\r\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-31\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"text_3\">\r\n    <g clip-path=\"url(#pb49fd601a8)\">\r\n     <!-- 2 -->\r\n     <g transform=\"translate(40.870103 273.519514)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 1228 531 \r\nL 3431 531 \r\nL 3431 0 \r\nL 469 0 \r\nL 469 531 \r\nQ 828 903 1448 1529 \r\nQ 2069 2156 2228 2338 \r\nQ 2531 2678 2651 2914 \r\nQ 2772 3150 2772 3378 \r\nQ 2772 3750 2511 3984 \r\nQ 2250 4219 1831 4219 \r\nQ 1534 4219 1204 4116 \r\nQ 875 4013 500 3803 \r\nL 500 4441 \r\nQ 881 4594 1212 4672 \r\nQ 1544 4750 1819 4750 \r\nQ 2544 4750 2975 4387 \r\nQ 3406 4025 3406 3419 \r\nQ 3406 3131 3298 2873 \r\nQ 3191 2616 2906 2266 \r\nQ 2828 2175 2409 1742 \r\nQ 1991 1309 1228 531 \r\nz\r\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-32\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"text_4\">\r\n    <g clip-path=\"url(#pb49fd601a8)\">\r\n     <!-- 3 -->\r\n     <g transform=\"translate(132.240852 142.163908)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 2597 2516 \r\nQ 3050 2419 3304 2112 \r\nQ 3559 1806 3559 1356 \r\nQ 3559 666 3084 287 \r\nQ 2609 -91 1734 -91 \r\nQ 1441 -91 1130 -33 \r\nQ 819 25 488 141 \r\nL 488 750 \r\nQ 750 597 1062 519 \r\nQ 1375 441 1716 441 \r\nQ 2309 441 2620 675 \r\nQ 2931 909 2931 1356 \r\nQ 2931 1769 2642 2001 \r\nQ 2353 2234 1838 2234 \r\nL 1294 2234 \r\nL 1294 2753 \r\nL 1863 2753 \r\nQ 2328 2753 2575 2939 \r\nQ 2822 3125 2822 3475 \r\nQ 2822 3834 2567 4026 \r\nQ 2313 4219 1838 4219 \r\nQ 1578 4219 1281 4162 \r\nQ 984 4106 628 3988 \r\nL 628 4550 \r\nQ 988 4650 1302 4700 \r\nQ 1616 4750 1894 4750 \r\nQ 2613 4750 3031 4423 \r\nQ 3450 4097 3450 3541 \r\nQ 3450 3153 3228 2886 \r\nQ 3006 2619 2597 2516 \r\nz\r\n\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-33\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"text_5\">\r\n    <g clip-path=\"url(#pb49fd601a8)\">\r\n     <!-- 4 -->\r\n     <g transform=\"translate(354.422078 35.502986)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 2419 4116 \r\nL 825 1625 \r\nL 2419 1625 \r\nL 2419 4116 \r\nz\r\nM 2253 4666 \r\nL 3047 4666 \r\nL 3047 1625 \r\nL 3713 1625 \r\nL 3713 1100 \r\nL 3047 1100 \r\nL 3047 0 \r\nL 2419 0 \r\nL 2419 1100 \r\nL 313 1100 \r\nL 313 1709 \r\nL 2253 4666 \r\nz\r\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-34\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pb49fd601a8\">\r\n   <rect height=\"288\" width=\"432\" x=\"7.2\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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"
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "sampler = dgl.dataloading.MultiLayerFullNeighborSampler(n_layers=2)\r\n",
    "dataloader = dgl.dataloading.NodeDataLoader(G, [4], sampler,\r\n",
    "                                            batch_size=1)\r\n",
    "\r\n",
    "input_nodes, output_nodes, blocks = next(iter(dataloader))      \r\n",
    "print(f'{input_nodes=}')                                    \r\n",
    "print(f'{output_nodes=}')                                    \r\n",
    "print(f'{blocks=}')                                    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "input_nodes=tensor([4, 3, 0, 2])\n",
      "output_nodes=tensor([4])\n",
      "blocks=[Block(num_src_nodes=4, num_dst_nodes=2, num_edges=3), Block(num_src_nodes=2, num_dst_nodes=1, num_edges=1)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "layer1 = gnn.SAGEConv(5, 3, aggregator_type='mean')\r\n",
    "layer2 = gnn.SAGEConv(3, 2, aggregator_type='mean')\r\n",
    "features = G.ndata['feat'][input_nodes]\r\n",
    "print(features)\r\n",
    "# если взять 4 узла из block[0] и выполнить рассылку сообщений, то получим\r\n",
    "# представления 2 узлов\r\n",
    "out = layer1(blocks[0], features)\r\n",
    "print(out)\r\n",
    "# если взять 2 узла из block[1] и выполнить рассылку сообщений, то получим\r\n",
    "# представления 1 узла\r\n",
    "out = layer2(blocks[1], out)\r\n",
    "print(out)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-1.3466,  0.0613,  1.2991,  0.9760, -1.2939],\n",
      "        [-1.3669, -0.5564,  1.5476,  0.3555,  0.6966],\n",
      "        [ 1.6469,  0.5162,  1.1806, -0.8277, -0.1649],\n",
      "        [ 0.3318,  1.2898,  0.5696, -0.2475, -0.5783]])\n",
      "tensor([[ 7.7012,  3.6908, -0.5703],\n",
      "        [ 0.0434,  2.5330,  3.9764]], grad_fn=<AddBackward0>)\n",
      "tensor([[ -2.0477, -22.9975]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`DGL` предоставляет возможности для реализации своей стратегии сэмплирования соседей.\r\n",
    "\r\n",
    "Базовый класс сэмплеров - `BlockSampler` - отвечает за генерацию списка MFGs, начиная с последнего слоя, при помощи метода `sample_blocks()`. Базовая реализация этого метода - идти от последнего слоя к первому, генерировать фронты и преобразовывать их в MFGs.\r\n",
    "\r\n",
    "Если требуется реализовать кастомное поведение, достаточно определить метод `sample_blocks()`. Он должен принимать на вход: \r\n",
    "1. Слой, для которого генерируется фронт\r\n",
    "2. Исходный граф\r\n",
    "3. Узлы, для которых на этом слое рассчитываются представления (`output_nodes` или `seed_nodes`)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# пример реализации простейшего сэмплера\r\n",
    "class MultiLayerFullNeighborSampler(dgl.dataloading.BlockSampler):\r\n",
    "    def __init__(self, n_layers):\r\n",
    "        super().__init__(n_layers)\r\n",
    "\r\n",
    "    def sample_frontier(self, block_id, g, seed_nodes):\r\n",
    "        frontier = dgl.in_subgraph(g, seed_nodes)\r\n",
    "        return frontier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Пример более сложного сэмплера, который позволяет сэмплировать небольшое количество соседей для получения сообщений"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "class MultiLayerNeighborSampler(dgl.dataloading.BlockSampler):\r\n",
    "    def __init__(self, fanouts):\r\n",
    "        super().__init__(len(fanouts))\r\n",
    "\r\n",
    "        # fanouts: список целых чисел: кол-ва соседей для сэмплинга на iм слое\r\n",
    "        self.fanouts = fanouts\r\n",
    "\r\n",
    "    def sample_frontier(self, block_id, g, seed_nodes):\r\n",
    "        fanout = self.fanouts[block_id]\r\n",
    "        if fanout is None:\r\n",
    "            frontier = dgl.in_subgraph(g, seed_nodes)\r\n",
    "        else:\r\n",
    "            frontier = dgl.sampling.sample_neighbors(g, seed_nodes, fanout)\r\n",
    "        return frontier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "После реализации собственного сэмплера, можно создать dataloader и итерироваться по нему, как и в случае уже готовых сэмплеров."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stochastic training for node classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "При работе с модулями из DGL перейти на работу с батчами достаточно просто - нужно в метод `forward` модели передавать не весь граф, а блоки; каждый блок соответствует очередному слою. Кол-во слоев должно быть известно заранее (на момент создания сэмплера)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class GCN(nn.Module):\r\n",
    "    def __init__(self, in_features, hidden_features, out_features):\r\n",
    "        super().__init__()\r\n",
    "        self.conv1 = gnn.GraphConv(in_features, hidden_features)\r\n",
    "        self.conv2 = gnn.GraphConv(hidden_features, out_features)\r\n",
    "\r\n",
    "    # def forward(self, g, x):\r\n",
    "    #     x = F.relu(self.conv1(g, x))\r\n",
    "    #     x = self.conv2(g, x)\r\n",
    "    #     return x\r\n",
    "\r\n",
    "    def forward(self, blocks, x):\r\n",
    "        x = F.relu(self.conv1(blocks[0], x))\r\n",
    "        x = self.conv2(blocks[1], x)\r\n",
    "        return x    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь цикл обучения выглядит так.\r\n",
    "\r\n",
    "Итерируемся по даталоадеру. На каждой итерации имеем тройку `input_nodes`, `output_nodes` и `blocks`. \r\n",
    "1. Загружаем все фичи для узлов из `input_nodes`; фичи всех остальных узлов можно не загружать. Если фичи уже лежат в `G.ndata`, то нужные их них можно получить, обратившись к `blocks[0].srcdata`\r\n",
    "2. Прогоняем каждый из блоков последовательно по слоям сети\r\n",
    "3. Подгружаем метки узлов для обучения. Если они уже лежали в `G.ndata`, то нужные их них можно получить, обратившись к `blocks[-1].dstdata`\r\n",
    "4. Считаем лосс и выполняем обратное распространение ошибки"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "from utils import load_reddit\r\n",
    "G, n_classes = load_reddit()\r\n",
    "G = G.subgraph(torch.randint(0, G.num_nodes(), (20_000, )))\r\n",
    "\r\n",
    "train_G = G.subgraph(G.ndata['train_mask'])\r\n",
    "val_G = G.subgraph(G.ndata['train_mask'] | G.ndata['val_mask'])\r\n",
    "test_G = G"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "train_nfeat = train_G.ndata.pop('features')\r\n",
    "val_nfeat = val_G.ndata.pop('features')\r\n",
    "test_nfeat = test_G.ndata.pop('features')\r\n",
    "train_labels = train_G.ndata.pop('labels')\r\n",
    "val_labels = val_G.ndata.pop('labels')\r\n",
    "test_labels = test_G.ndata.pop('labels')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "train_nid = train_G.ndata['train_mask'].nonzero().flatten()\r\n",
    "val_nid = val_G.ndata['val_mask'].nonzero().flatten()\r\n",
    "test_nid = (~(test_G.ndata['train_mask'] | test_G.ndata['val_mask'])).nonzero().flatten()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "class GCN(nn.Module):\r\n",
    "    def __init__(self, n_inputs, n_hidden, n_outputs):\r\n",
    "        super().__init__()\r\n",
    "        self.conv1 = gnn.SAGEConv(n_inputs, n_hidden, aggregator_type='mean', activation=F.relu)\r\n",
    "        self.conv2 = gnn.SAGEConv(n_hidden, n_outputs, aggregator_type='mean')\r\n",
    "\r\n",
    "    def forward(self, blocks, features):\r\n",
    "        assert len(blocks) == 2\r\n",
    "        out = self.conv1(blocks[0], features)\r\n",
    "        out = self.conv2(blocks[1], out)\r\n",
    "        return out\r\n",
    "\r\n",
    "    def inference(self, G, features):\r\n",
    "        out = self.conv1(G, features)\r\n",
    "        out = self.conv2(G, out)\r\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "fanouts = [10, 25]\r\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler(fanouts)\r\n",
    "dataloader = dgl.dataloading.NodeDataLoader(train_G, train_nid, sampler,\r\n",
    "                                            batch_size=256, shuffle=True,\r\n",
    "                                            drop_last=False)\r\n",
    "\r\n",
    "model = GCN(train_nfeat.shape[1], 16, n_classes)\r\n",
    "\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)   \r\n",
    "\r\n",
    "for epoch in range(20):\r\n",
    "    for step, (input_nodes, output_nodes, blocks) in enumerate(dataloader):\r\n",
    "        batch_inputs = train_nfeat[input_nodes]\r\n",
    "        batch_labels = train_labels[output_nodes]\r\n",
    "        \r\n",
    "        preds = model(blocks, batch_inputs)\r\n",
    "        loss = criterion(preds, batch_labels)\r\n",
    "        \r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        optimizer.zero_grad()\r\n",
    "\r\n",
    "        if not step % 20:\r\n",
    "            acc = (preds.argmax(dim=1) == batch_labels).sum() / len(preds)\r\n",
    "            print('Epoch {:05d} | Step {:05d} | Loss {:.4f} | Train Acc {:.4f}'.format(\r\n",
    "                        epoch, step, loss.item(), acc.item()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 00000 | Step 00000 | Loss 5.5970 | Train Acc 0.0156\n",
      "Epoch 00000 | Step 00020 | Loss 4.0209 | Train Acc 0.1016\n",
      "Epoch 00000 | Step 00040 | Loss 3.4841 | Train Acc 0.1758\n",
      "Epoch 00001 | Step 00000 | Loss 3.5828 | Train Acc 0.1602\n",
      "Epoch 00001 | Step 00020 | Loss 3.2825 | Train Acc 0.2031\n",
      "Epoch 00001 | Step 00040 | Loss 3.0412 | Train Acc 0.2656\n",
      "Epoch 00002 | Step 00000 | Loss 2.9172 | Train Acc 0.2695\n",
      "Epoch 00002 | Step 00020 | Loss 2.8811 | Train Acc 0.2539\n",
      "Epoch 00002 | Step 00040 | Loss 2.5978 | Train Acc 0.3125\n",
      "Epoch 00003 | Step 00000 | Loss 2.8267 | Train Acc 0.2812\n",
      "Epoch 00003 | Step 00020 | Loss 2.7243 | Train Acc 0.3516\n",
      "Epoch 00003 | Step 00040 | Loss 2.7118 | Train Acc 0.2734\n",
      "Epoch 00004 | Step 00000 | Loss 2.5340 | Train Acc 0.3594\n",
      "Epoch 00004 | Step 00020 | Loss 2.3566 | Train Acc 0.3750\n",
      "Epoch 00004 | Step 00040 | Loss 2.4719 | Train Acc 0.3750\n",
      "Epoch 00005 | Step 00000 | Loss 2.3187 | Train Acc 0.4141\n",
      "Epoch 00005 | Step 00020 | Loss 2.2216 | Train Acc 0.4258\n",
      "Epoch 00005 | Step 00040 | Loss 2.3096 | Train Acc 0.3828\n",
      "Epoch 00006 | Step 00000 | Loss 2.0490 | Train Acc 0.4453\n",
      "Epoch 00006 | Step 00020 | Loss 2.0000 | Train Acc 0.4688\n",
      "Epoch 00006 | Step 00040 | Loss 2.1509 | Train Acc 0.4609\n",
      "Epoch 00007 | Step 00000 | Loss 1.9770 | Train Acc 0.4844\n",
      "Epoch 00007 | Step 00020 | Loss 1.8275 | Train Acc 0.5508\n",
      "Epoch 00007 | Step 00040 | Loss 2.1001 | Train Acc 0.4492\n",
      "Epoch 00008 | Step 00000 | Loss 2.0552 | Train Acc 0.4414\n",
      "Epoch 00008 | Step 00020 | Loss 1.7526 | Train Acc 0.5156\n",
      "Epoch 00008 | Step 00040 | Loss 1.8219 | Train Acc 0.5391\n",
      "Epoch 00009 | Step 00000 | Loss 1.7009 | Train Acc 0.5547\n",
      "Epoch 00009 | Step 00020 | Loss 1.8071 | Train Acc 0.5000\n",
      "Epoch 00009 | Step 00040 | Loss 1.8608 | Train Acc 0.5000\n",
      "Epoch 00010 | Step 00000 | Loss 1.7696 | Train Acc 0.5117\n",
      "Epoch 00010 | Step 00020 | Loss 1.6425 | Train Acc 0.5703\n",
      "Epoch 00010 | Step 00040 | Loss 1.6363 | Train Acc 0.5781\n",
      "Epoch 00011 | Step 00000 | Loss 1.4305 | Train Acc 0.5938\n",
      "Epoch 00011 | Step 00020 | Loss 1.5322 | Train Acc 0.5898\n",
      "Epoch 00011 | Step 00040 | Loss 1.6800 | Train Acc 0.5352\n",
      "Epoch 00012 | Step 00000 | Loss 1.6164 | Train Acc 0.5312\n",
      "Epoch 00012 | Step 00020 | Loss 1.5053 | Train Acc 0.5859\n",
      "Epoch 00012 | Step 00040 | Loss 1.5633 | Train Acc 0.5781\n",
      "Epoch 00013 | Step 00000 | Loss 1.4709 | Train Acc 0.5586\n",
      "Epoch 00013 | Step 00020 | Loss 1.6133 | Train Acc 0.5352\n",
      "Epoch 00013 | Step 00040 | Loss 1.4692 | Train Acc 0.6094\n",
      "Epoch 00014 | Step 00000 | Loss 1.4902 | Train Acc 0.5586\n",
      "Epoch 00014 | Step 00020 | Loss 1.3928 | Train Acc 0.6172\n",
      "Epoch 00014 | Step 00040 | Loss 1.4228 | Train Acc 0.6133\n",
      "Epoch 00015 | Step 00000 | Loss 1.3753 | Train Acc 0.5820\n",
      "Epoch 00015 | Step 00020 | Loss 1.2309 | Train Acc 0.6562\n",
      "Epoch 00015 | Step 00040 | Loss 1.3302 | Train Acc 0.6211\n",
      "Epoch 00016 | Step 00000 | Loss 1.2760 | Train Acc 0.6289\n",
      "Epoch 00016 | Step 00020 | Loss 1.3187 | Train Acc 0.6406\n",
      "Epoch 00016 | Step 00040 | Loss 1.4243 | Train Acc 0.6016\n",
      "Epoch 00017 | Step 00000 | Loss 1.4189 | Train Acc 0.5938\n",
      "Epoch 00017 | Step 00020 | Loss 1.3760 | Train Acc 0.5820\n",
      "Epoch 00017 | Step 00040 | Loss 1.2077 | Train Acc 0.6758\n",
      "Epoch 00018 | Step 00000 | Loss 1.1389 | Train Acc 0.6602\n",
      "Epoch 00018 | Step 00020 | Loss 1.1492 | Train Acc 0.6953\n",
      "Epoch 00018 | Step 00040 | Loss 1.3949 | Train Acc 0.6250\n",
      "Epoch 00019 | Step 00000 | Loss 1.3165 | Train Acc 0.6172\n",
      "Epoch 00019 | Step 00020 | Loss 1.1975 | Train Acc 0.6406\n",
      "Epoch 00019 | Step 00040 | Loss 1.2104 | Train Acc 0.6836\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "val_preds = model.inference(val_G, val_nfeat)\r\n",
    "acc = (val_preds.argmax(dim=1) == val_labels).sum() / len(val_labels)\r\n",
    "print(f'{acc:.4f}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6370\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Heterogenious graph stochastic training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "class RGCN(nn.Module):\r\n",
    "    def __init__(self, n_inputs, n_hidden, n_outputs, rel_names):\r\n",
    "        super().__init__()\r\n",
    "        conv1_modules = {rel: gnn.GraphConv(n_inputs, n_hidden) for rel in rel_names}\r\n",
    "        conv2_modules = {rel: gnn.GraphConv(n_hidden, n_outputs) for rel in rel_names}\r\n",
    "        self.conv1 = gnn.HeteroGraphConv(conv1_modules, aggregate='sum')\r\n",
    "        self.conv2 = gnn.HeteroGraphConv(conv2_modules, aggregate='sum')\r\n",
    "\r\n",
    "    def forward(self, blocks, features):\r\n",
    "        out = self.conv1(blocks[0], features)\r\n",
    "        out = {k: F.relu(v) for k, v in out.items()}\r\n",
    "        out = self.conv2(blocks[1], out)\r\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "from utils import create_heterograph\r\n",
    "\r\n",
    "G = create_heterograph()\r\n",
    "model = RGCN(G.n_hetero_features, \r\n",
    "             20, \r\n",
    "             G.n_user_classes,\r\n",
    "             G.etypes)\r\n",
    "\r\n",
    "user_feats = G.nodes['user'].data['feature']\r\n",
    "item_feats = G.nodes['item'].data['feature']\r\n",
    "node_features = {ntype: G.nodes[ntype].data['feature'] for ntype in G.ntypes}\r\n",
    "labels = G.nodes['user'].data['label']\r\n",
    "train_mask = G.nodes['user'].data['train_mask']\r\n",
    "train_nid_dict = {'user': G.nodes['user'].data['train_mask'].nonzero().flatten()}\r\n",
    "\r\n",
    "sampler = dgl.dataloading.MultiLayerFullNeighborSampler(2)\r\n",
    "dataloader = dgl.dataloading.NodeDataLoader(G, train_nid_dict, sampler,\r\n",
    "                                            batch_size=32, shuffle=True)\r\n",
    "\r\n",
    "optimizer = optim.Adam(model.parameters(), lr=.01)\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "for epoch in range(20):\r\n",
    "    for step, (input_nodes, output_nodes, blocks) in enumerate(dataloader):\r\n",
    "        # forward\r\n",
    "        batch_node_features = {ntype: node_features[ntype][n_ids] \r\n",
    "                                   for ntype, n_ids in input_nodes.items()}\r\n",
    "        batch_labels = labels[output_nodes['user']]\r\n",
    "\r\n",
    "        logits_by_type = model(blocks, batch_node_features)\r\n",
    "        # обучаемся только на пользователях\r\n",
    "        logits = logits_by_type['user']\r\n",
    "        loss = criterion(logits, batch_labels)\r\n",
    "        # backward\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        optimizer.zero_grad()\r\n",
    "        if not step % 10:\r\n",
    "            acc = (logits.argmax(dim=1) == batch_labels).sum() / len(preds)\r\n",
    "            print('Epoch {:05d} | Step {:05d} | Loss {:.4f} | Train Acc {:.4f}'.format(\r\n",
    "                        epoch, step, loss.item(), acc.item()))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 00000 | Step 00000 | Loss 3.4874 | Train Acc 0.0465\n",
      "Epoch 00000 | Step 00010 | Loss 2.4812 | Train Acc 0.0349\n",
      "Epoch 00001 | Step 00000 | Loss 1.7108 | Train Acc 0.0523\n",
      "Epoch 00001 | Step 00010 | Loss 1.7010 | Train Acc 0.0581\n",
      "Epoch 00002 | Step 00000 | Loss 1.6059 | Train Acc 0.0523\n",
      "Epoch 00002 | Step 00010 | Loss 1.4828 | Train Acc 0.0698\n",
      "Epoch 00003 | Step 00000 | Loss 1.2961 | Train Acc 0.0872\n",
      "Epoch 00003 | Step 00010 | Loss 1.5904 | Train Acc 0.0523\n",
      "Epoch 00004 | Step 00000 | Loss 1.3534 | Train Acc 0.0872\n",
      "Epoch 00004 | Step 00010 | Loss 1.4935 | Train Acc 0.0756\n",
      "Epoch 00005 | Step 00000 | Loss 1.0347 | Train Acc 0.1105\n",
      "Epoch 00005 | Step 00010 | Loss 1.5249 | Train Acc 0.0581\n",
      "Epoch 00006 | Step 00000 | Loss 1.2868 | Train Acc 0.1047\n",
      "Epoch 00006 | Step 00010 | Loss 1.2713 | Train Acc 0.0988\n",
      "Epoch 00007 | Step 00000 | Loss 1.3194 | Train Acc 0.1047\n",
      "Epoch 00007 | Step 00010 | Loss 1.1724 | Train Acc 0.1279\n",
      "Epoch 00008 | Step 00000 | Loss 1.3073 | Train Acc 0.0814\n",
      "Epoch 00008 | Step 00010 | Loss 1.1463 | Train Acc 0.1105\n",
      "Epoch 00009 | Step 00000 | Loss 1.3077 | Train Acc 0.0814\n",
      "Epoch 00009 | Step 00010 | Loss 1.0036 | Train Acc 0.1221\n",
      "Epoch 00010 | Step 00000 | Loss 1.1399 | Train Acc 0.1279\n",
      "Epoch 00010 | Step 00010 | Loss 1.0961 | Train Acc 0.1105\n",
      "Epoch 00011 | Step 00000 | Loss 1.1202 | Train Acc 0.1047\n",
      "Epoch 00011 | Step 00010 | Loss 0.8746 | Train Acc 0.1337\n",
      "Epoch 00012 | Step 00000 | Loss 1.1314 | Train Acc 0.1105\n",
      "Epoch 00012 | Step 00010 | Loss 1.1247 | Train Acc 0.1163\n",
      "Epoch 00013 | Step 00000 | Loss 1.0310 | Train Acc 0.1105\n",
      "Epoch 00013 | Step 00010 | Loss 0.9477 | Train Acc 0.1279\n",
      "Epoch 00014 | Step 00000 | Loss 0.9529 | Train Acc 0.1221\n",
      "Epoch 00014 | Step 00010 | Loss 0.9130 | Train Acc 0.1221\n",
      "Epoch 00015 | Step 00000 | Loss 0.9316 | Train Acc 0.1163\n",
      "Epoch 00015 | Step 00010 | Loss 0.8600 | Train Acc 0.1105\n",
      "Epoch 00016 | Step 00000 | Loss 0.7759 | Train Acc 0.1337\n",
      "Epoch 00016 | Step 00010 | Loss 0.8458 | Train Acc 0.1163\n",
      "Epoch 00017 | Step 00000 | Loss 0.7958 | Train Acc 0.1163\n",
      "Epoch 00017 | Step 00010 | Loss 1.1845 | Train Acc 0.0930\n",
      "Epoch 00018 | Step 00000 | Loss 0.7862 | Train Acc 0.1221\n",
      "Epoch 00018 | Step 00010 | Loss 0.9099 | Train Acc 0.1279\n",
      "Epoch 00019 | Step 00000 | Loss 0.7778 | Train Acc 0.1337\n",
      "Epoch 00019 | Step 00010 | Loss 0.9260 | Train Acc 0.1047\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b06e6ab994fc15ce23aa05c7ffef0f9130e5f92563bdff97ffc0fa050e903d35"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('gcn': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}